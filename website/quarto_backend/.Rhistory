install.packages("renv")
renv::activate()
renv::activate()
renv::status()
reticulate::repl_python()
knitr::opts_chunk$set(echo = TRUE)
# Set seed
set.seed(123)
# Fit ridge regression model
X = model.matrix(player_pointadv ~., data = df) #create numeric matrix with intercept added
# Load libraries
require(ISLR)
require(MASS)
require(glmnet)
require(leaps)
set.seed(123)
# Read data
df <- read.csv("../../data/mls_subset_selection.csv")
# Remove factor variables
df <- subset(df, select = -c(Team, Position, Roleplayerdummyvariable))
df$X = NULL
# Split data into 80/20
train.idx = sample(length(df[,1]), 0.8 * length(df[,1])) #sample rows
train = df[train.idx,] #set train
test = df[-train.idx,] #set test
# Write train and test csv
write.csv(train, "../../data/train.csv", row.names=FALSE)
write.csv(test, "../../data/test.csv", row.names=FALSE)
# Check dimensions to confirm split
dim(train)
dim(test)
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
#### Calculate evaluation metrics #####
# MSE
m1.mse <- mean((df$player_pointadv[-train.idx] - m1.pred)^2)
print(paste0("The test MSE is: ", round(m1.mse, 2)))
# RMSE
m1.rmse <- sqrt(mean((df$player_pointadv[-train.idx] - m1.pred)^2))
print(paste0("The test RMSE is: ", round(m1.rmse, 2)))
# MAE
library(Metrics)
m1.mae <- mae(test$player_pointadv, m1.pred)
print(paste0("The test MAE is: ", round(m1.mae, 2)))
# R Squared
m1.rsquared <- summary(m1)$r.squared
print(paste0("The R Squared is: ", round(m1.rsquared, 2)))
# Set seed
set.seed(123)
# Fit ridge regression model
X = model.matrix(player_pointadv ~., data = df) #create numeric matrix with intercept added
lambdas <- 10^seq(3, -2, by = -.1) #set lambdas
X = X[,2:ncol(X)] #subset X
# Split train and test
X.train = X[train.idx,] #set X train
X.test = X[-train.idx,] #set X test
y = df$player_pointadv[train.idx] #set y
cv.ridge = cv.glmnet(X.train, y, alpha = 0, lambda = lambdas) #create ridge with log lambda range
# Plot test MSE
jpeg('rplot.jpg', res = 300, quality=0.90, width = 7, height=7, units = "in")
plot(cv.ridge)
title(main = "Mean Squared Error across various Lambda values", line = 2.5)
dev.off()
# Find optimal lambda
opt_lambda <- cv.ridge$lambda.min
print(paste0("The optimal lambda is: ", opt_lambda))
# Fit ridge again using chosen lambda
m2 = glmnet(X.train, y, alpha=0, lambda=opt_lambda) #fit
# Find how many variables are left in the final ridge regression model
coef_m2 <- coef(m2, s = opt_lambda)
num_vars_m2 <- sum(coef_m2[-1] != 0) # Exclude the intercept term
print(paste0("Number of variables left in the final ridge regression model m2: ", num_vars_m2))
# Predict on test
m2.pred = predict.glmnet(m2, newx = X.test, s=10, type="response")
#### Calculate evaluation metrics #####
# MSE
m2.mse = mean((df$player_pointadv[-train.idx] - m2.pred)^2) #find mse
print(paste0("The test MSE is: ", round(m2.mse, 2)))
# RMSE
m2.rmse = sqrt(mean((df$player_pointadv[-train.idx] - m2.pred)^2)) #find rmse
print(paste0("The test RMSE is: ", round(m1.rmse, 2))) #print rmse
# MAE
m2.mae <- mae(test$player_pointadv, m2.pred)
print(paste0("The test MAE is: ", round(m2.mae, 2)))
# R Squared
m2.rsquared <- 1 - (sum((m2.pred - test$player_pointadv)^2) / sum((test$player_pointadv - mean(test$player_pointadv))^2))
print(paste0("The R Squared is: ", round(m2.rsquared, 2)))
# Load libraries
require(ISLR)
require(MASS)
require(glmnet)
require(leaps)
set.seed(123)
# Read data
df <- read.csv("../../data/mls_subset_selection.csv")
# Remove factor variables
df <- subset(df, select = -c(Team, Position, Roleplayerdummyvariable))
df$X = NULL
# Split data into 80/20
train.idx = sample(length(df[,1]), 0.8 * length(df[,1])) #sample rows
train = df[train.idx,] #set train
test = df[-train.idx,] #set test
# Write train and test csv
write.csv(train, "../../data/train.csv", row.names=FALSE)
write.csv(test, "../../data/test.csv", row.names=FALSE)
# Check dimensions to confirm split
dim(train)
dim(test)
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
#### Calculate evaluation metrics #####
# MSE
m1.mse <- mean((df$player_pointadv[-train.idx] - m1.pred)^2)
print(paste0("The test MSE is: ", round(m1.mse, 2)))
# RMSE
m1.rmse <- sqrt(mean((df$player_pointadv[-train.idx] - m1.pred)^2))
print(paste0("The test RMSE is: ", round(m1.rmse, 2)))
# MAE
library(Metrics)
m1.mae <- mae(test$player_pointadv, m1.pred)
print(paste0("The test MAE is: ", round(m1.mae, 2)))
# R Squared
m1.rsquared <- summary(m1)$r.squared
print(paste0("The R Squared is: ", round(m1.rsquared, 2)))
plot(m1$residuals)
title(main= "Residual Plot")
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
title(main= "Linear Regression Residual Plot")
xlabel <- "Fitted Values"
xlabel <- substitute(paste(italic(italic(xlabel))))
xlabel <- as.expression(xlabel)
xlabel <- list(label=xlabel, cex.lab=1.2)
axis(1, at=seq(-4,4,by=1), **xlabel**)
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
title(main= "Linear Regression Residual Plot")
xlabel <- "Fitted Values"
xlabel <- substitute(paste(italic(italic(xlabel))))
xlabel <- as.expression(xlabel)
xlabel <- list(label=xlabel, cex.lab=1.2)
axis(1, at=seq(-4,4,by=1), xlabel)
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
title(main= "Linear Regression Residual Plot")
xlabel <- "Fitted Values"
xlabel <- substitute(paste(italic(italic(xlabel))))
xlabel <- as.expression(xlabel)
xlabel <- list(label=xlabel, cex.lab=1.2)
axis(1, xlabel)
#### Calculate evaluation metrics #####
# MSE
m1.mse <- mean((df$player_pointadv[-train.idx] - m1.pred)^2)
print(paste0("The test MSE is: ", round(m1.mse, 2)))
# RMSE
m1.rmse <- sqrt(mean((df$player_pointadv[-train.idx] - m1.pred)^2))
print(paste0("The test RMSE is: ", round(m1.rmse, 2)))
# MAE
library(Metrics)
m1.mae <- mae(test$player_pointadv, m1.pred)
print(paste0("The test MAE is: ", round(m1.mae, 2)))
# R Squared
m1.rsquared <- summary(m1)$r.squared
print(paste0("The R Squared is: ", round(m1.rsquared, 2)))
?title
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
title(main= "Linear Regression Residual Plot", xlab = "Index", ylab = "Residuals")
#### Calculate evaluation metrics #####
# MSE
m1.mse <- mean((df$player_pointadv[-train.idx] - m1.pred)^2)
print(paste0("The test MSE is: ", round(m1.mse, 2)))
# RMSE
m1.rmse <- sqrt(mean((df$player_pointadv[-train.idx] - m1.pred)^2))
print(paste0("The test RMSE is: ", round(m1.rmse, 2)))
# MAE
library(Metrics)
m1.mae <- mae(test$player_pointadv, m1.pred)
print(paste0("The test MAE is: ", round(m1.mae, 2)))
# R Squared
m1.rsquared <- summary(m1)$r.squared
print(paste0("The R Squared is: ", round(m1.rsquared, 2)))
# Set seed
set.seed(123)
# Fit linear model
m1 <- lm(player_pointadv ~ ., data = train)
# Predict on test
m1.pred <- predict.lm(m1, newdata = test)
# Plot residuals
plot(m1$residuals)
title(main= "Linear Regression Residual Plot")
#### Calculate evaluation metrics #####
# MSE
m1.mse <- mean((df$player_pointadv[-train.idx] - m1.pred)^2)
print(paste0("The test MSE is: ", round(m1.mse, 2)))
# RMSE
m1.rmse <- sqrt(mean((df$player_pointadv[-train.idx] - m1.pred)^2))
print(paste0("The test RMSE is: ", round(m1.rmse, 2)))
# MAE
library(Metrics)
m1.mae <- mae(test$player_pointadv, m1.pred)
print(paste0("The test MAE is: ", round(m1.mae, 2)))
# R Squared
m1.rsquared <- summary(m1)$r.squared
print(paste0("The R Squared is: ", round(m1.rsquared, 2)))
