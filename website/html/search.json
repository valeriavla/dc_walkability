[
  {
    "objectID": "authors.html#cynthia-ng-cn524georgetown.edu",
    "href": "authors.html#cynthia-ng-cn524georgetown.edu",
    "title": "Authors",
    "section": "Cynthia Ng cn524@georgetown.edu",
    "text": "Cynthia Ng cn524@georgetown.edu"
  },
  {
    "objectID": "authors.html#katherine-mead-kam515georgetown.edu",
    "href": "authors.html#katherine-mead-kam515georgetown.edu",
    "title": "Authors",
    "section": "Katherine Mead kam515@georgetown.edu",
    "text": "Katherine Mead kam515@georgetown.edu"
  },
  {
    "objectID": "authors.html#madelyne-ventura-mv790georgetown.edu",
    "href": "authors.html#madelyne-ventura-mv790georgetown.edu",
    "title": "Authors",
    "section": "Madelyne Ventura mv790@georgetown.edu",
    "text": "Madelyne Ventura mv790@georgetown.edu"
  },
  {
    "objectID": "authors.html#valeria-vera-lagos-vv188georgetown.edu",
    "href": "authors.html#valeria-vera-lagos-vv188georgetown.edu",
    "title": "Authors",
    "section": "Valeria Vera Lagos vv188@georgetown.edu",
    "text": "Valeria Vera Lagos vv188@georgetown.edu"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Walkability impact in D.C.",
    "section": "",
    "text": "Overall, we explored the ease of access in various neighborhoods by foot and by bike, the correlation of walkability to socioeconomic and health outcomes, and sentiment around walkability in Washington, D.C. First, we see that walkability is associated with mixed socioeconomic outcomes, based on geographic area: while all outer parts of Washington, D.C. have low walkability, the top edges have higher car ownership and socioeconomic outcomes, whereas the low edges have low car ownership and poorer socioeconomic outcomes. Second, we see that low walkability is generally associated with poorer health outcomes, which makes sense because having decreased access to walking would limit mobility and health outcomes. After examining walkability and its assocation with various outcomes, we examined bikability and noticed that there are more neighborhood-downtown bike lanes and fewer neighborhood-neighborhood bike lanes. Given that housing and spending are generally higher in downtown areas, this trend makes it more expensive and unsafe to travel between lower-income areas. Finally, we investigated public sentiment on walking, biking, and cars in Washington, D.C. and discovered that people tend to comment on bicycles more favorably than on walking or driving, all categories also draw criticism.\nIt is important to note that various socioeconomic and health outcomes as well as walkability are interconnected and contribute to a complex web of influences on each other. Overall, our findings show that higher walkability in neighborhoods can promote physical activity, access to healthy food, and overall environmental and socioeconomic well-being, which in turn can positively impact various health metrics. If we had more time to conduct this study, we would love to explore the interactions between socioeconomic and health metrics to help us contextualize the relationship between walkability and such outcomes, so to have a better understanding of the causal and correlational relationships between these factors. For our text data, we would also further contextualize the sentiment analysis and differentiate between sentences like “I hate that walkability in Washington, D.C. is bad” and “I hate walking in Washington, D.C.” to obtain more accurate findings.\nAs Washington, D.C. is among the most walkable cities in the US, we hope that this study can increase awareness of the importance of walkability and even inspire future initiatives in improving walkability in Washington, D.C. and other cities too. Having an equitable access to amenities like grocery stores and community health centers is vital to positive outcomes, and we hope that this study might inspire you to find ways to learn more about and promote walkability in where you live."
  },
  {
    "objectID": "conclusion.html#future-work",
    "href": "conclusion.html#future-work",
    "title": "Conclusion",
    "section": "Future work",
    "text": "Future work\nWhat we were missing how to improve next steps"
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Cleaning and Exploration",
    "section": "",
    "text": "Processes for cleaning and tidying data. Right now all processes are on mutiple jupyter notebooks under code/data_processing. Will be gathered together in this section.\nAliquam eu iaculis tellus, a lacinia lacus. Donec at placerat orci, suscipit maximus neque. Vivamus aliquet accumsan ultricies. Vivamus turpis mi, hendrerit nec massa vitae, ultricies laoreet ipsum. Cras et libero sem. Etiam at lectus ut lacus iaculis pretium. Phasellus cursus, justo in imperdiet commodo, justo odio commodo urna, in scelerisque diam dolor ac mauris. Fusce sapien tortor, dictum vitae nisi quis, rutrum faucibus est. Integer maximus eleifend efficitur. Nullam ut risus ac neque vehicula gravida et pulvinar orci. Curabitur nec hendrerit quam.\nFusce ac eleifend est, et scelerisque mauris. Aliquam dignissim sem id libero mattis varius. Integer tempus semper lacus eget eleifend. Aenean iaculis, dui in commodo pharetra, justo nisl porttitor ex, a posuere nisi erat sit amet enim. Nulla mattis nec dui ac convallis. Quisque gravida mauris sed posuere dignissim. Nam placerat nunc mattis ultrices scelerisque. Etiam lectus odio, cursus a neque a, consectetur dictum urna."
  },
  {
    "objectID": "data_cleaning.html#data-overview-after-cleaning",
    "href": "data_cleaning.html#data-overview-after-cleaning",
    "title": "Cleaning",
    "section": "Data Overview after cleaning",
    "text": "Data Overview after cleaning\nShape and size of our data, transformations we did, how did we merge it, which files contain the data now"
  },
  {
    "objectID": "data_collection.html",
    "href": "data_collection.html",
    "title": "Collection",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut maximus sem eu augue cursus maximus. Proin lacus neque, sollicitudin et vestibulum ac, placerat sit amet massa. Phasellus ac eleifend ligula, id elementum felis. Nam ac turpis efficitur, dapibus ipsum at, mollis nisi. Interdum et malesuada fames ac ante ipsum primis in faucibus. Maecenas mattis enim at ultrices maximus. Aenean vitae vehicula lorem, in maximus massa. Donec hendrerit commodo viverra."
  },
  {
    "objectID": "data_collection.html#datasets-gathered",
    "href": "data_collection.html#datasets-gathered",
    "title": "Collection",
    "section": "Datasets gathered",
    "text": "Datasets gathered\nDatasets and how did we gather them\n\nByclicles\nWalkability\nHealth\nSentiment\nIncome\n\nAPI, websites (include links), problems with the data …\n\nBicycles\nThe objective of this data set was to obtain insights of x,y,z\n\n\nHealth"
  },
  {
    "objectID": "data_exploration.html",
    "href": "data_exploration.html",
    "title": "Exploration",
    "section": "",
    "text": "Processes for exploring data and preview of results"
  },
  {
    "objectID": "findings.html",
    "href": "findings.html",
    "title": "Findings",
    "section": "",
    "text": "Main findings full narrative summary and final visualizations"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Walkability in D.C.",
    "section": "",
    "text": "Did you know…"
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Walkability in D.C.",
    "section": "Objective",
    "text": "Objective\nObjective of this analysis"
  },
  {
    "objectID": "index.html#questions",
    "href": "index.html#questions",
    "title": "Walkability in D.C.",
    "section": "Questions",
    "text": "Questions\nData Science questions"
  },
  {
    "objectID": "index.html#bibliography",
    "href": "index.html#bibliography",
    "title": "Walkability in D.C.",
    "section": "Bibliography",
    "text": "Bibliography\nValeria to add citations feel free to list the resources you are using here\n1.https://www.usnews.com/news/cities/articles/2020-10-16/us-cities-trail-behind-global-peers-in-walkability-report-finds 2. Glaeser, E. L., and Kahn, M. E. (2004). “Sprawl and Urban Growth,” in Handbook of Regional and Urban Economics (Elsevier), 2481–2527. doi:10.1016/s1574-0080(04)80013-0"
  },
  {
    "objectID": "index.html#how-is-walkabilty-associated-with-socioeconomic-outcomes-in-washington-d.c.",
    "href": "index.html#how-is-walkabilty-associated-with-socioeconomic-outcomes-in-washington-d.c.",
    "title": "Walkability in D.C.",
    "section": "1. How is walkabilty associated with socioeconomic outcomes in Washington, D.C.?",
    "text": "1. How is walkabilty associated with socioeconomic outcomes in Washington, D.C.?\n\n\nCode\nimport altair as alt\nimport pandas as pd\nimport geopandas as gpd\nfrom pathlib import Path\nimport requests\nimport numpy as np\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\"\"\"\nIMPORT DATA\n\"\"\"\n\n# define data directory\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nraw_data_dir = Path().absolute().parent.absolute().parent/\"data\"/\"raw_data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\n\n# import data\nwalkability = pd.read_csv(raw_data_dir/\"joined_depression_cre_walkability.csv\")\nwalkability.loc[:, 'geoid_tract_20'] = walkability.geoid_tract_20.astype(str)\nnation = pd.read_csv(data_dir/\"cleaned_data\"/\"nation-joined_depression_cre_walkability.csv\")\n\n# Ingest GEOJSON file of census tracts in DC and grab json\nreq_dc = requests.get('https://raw.githubusercontent.com/arcee123/GIS_GEOJSON_CENSUS_TRACTS/master/11.geojson')\njson_dc = req_dc.json()\n\n# create geopandas dataframe and add in the walkability / outcomes data\ngeo_df = gpd.GeoDataFrame.from_features((json_dc))\nmerged_df = geo_df.merge(walkability,\n                         how = 'left',\n                         left_on = 'GEOID',\n                         right_on='geoid_tract_20')\n\n\n\n\"\"\"\nNORMALIZE SCORES ACROSS ALL METRICS\n\"\"\"\n\n# convert the walkability score into a scale from 0 to 100 to make it more easier to interpret\n# original range 1-20\n# new desired range: 0-100\noriginal_range_min = 1\noriginal_range_max = 20\nnew_range_max = 100\nnew_range_min = 0 \n\nmerged_df.loc[:, 'walkability_score_scaled'] = merged_df.loc[:, 'walkability_score'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\nnation.loc[:, 'walkability_score_scaled'] = nation.loc[:, 'walkability_score'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\n\n# convert the income inequality index score into a scale from 0 to 100 to make it easier to interpret\n# original range 0-1\n# new desired range: 0-100\noriginal_range_min = 0\noriginal_range_max = 1\nnew_range_max = 100\nnew_range_min = 0 \n\nmerged_df.loc[:, 'income_inequality_gini_index'] = merged_df.loc[:, 'income_inequality_gini_index'].apply(lambda x: x if x >= 0 else np.nan)\nmerged_df.loc[:, 'income_inequality_gini_index_scaled'] = merged_df.loc[:, 'income_inequality_gini_index'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\nnation.loc[:, 'income_inequality_gini_index'] = nation.loc[:, 'income_inequality_gini_index'].apply(lambda x: x if x >= 0 else np.nan)\nnation.loc[:, 'income_inequality_gini_index_scaled'] = nation.loc[:, 'income_inequality_gini_index'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\n\n\n# define columns to report\noutcomes_cols = ['walkability_score_scaled',\n                 'below_poverty_level_perc',\n                 'income_inequality_gini_index_scaled',\n                 'hs_grad_perc',\n                 'households_no_vehicle_perc']\n\nfor i in outcomes_cols:\n    merged_df[i] = merged_df[i].apply(lambda x: x if x >= 0 else np.nan)\n    nation[i] = nation[i].apply(lambda x: x if x >= 0 else np.nan)\n    \n# flip metric to be percent of households with a car\nmerged_df.loc[:, 'households_w_vehicle'] = 100 - merged_df['households_no_vehicle_perc']\nnation.loc[:, 'households_w_vehicle'] = 100 - nation['households_no_vehicle_perc']\n\n\n\n\"\"\"\nCLEAN COLUMN NAMES\n\"\"\"\ncol_mapping = {'below_poverty_level_perc': '% Below Poverty Level',\n               'income_inequality_gini_index_scaled': 'Income Inequality Gini Score',\n               'hs_grad_perc': '% HS or Higher Degree',\n               'households_w_vehicle': '% with a Vehicle',\n               'walkability_score_scaled': 'Walkability Score',\n               'neighborhood_name': 'Neighborhood Name'}\n\nmerged_df = merged_df.rename(col_mapping, axis='columns')\n\n\n\"\"\"\nRE-FORMAT DATA\n\"\"\"\n# turn the dataframe into long data so that the bar chart can be created with each outcome as a bar\nneighborhood_df = pd.melt(merged_df,\n                          id_vars = 'Neighborhood Name',\n                          value_vars = col_mapping.values())\n\nneighborhood_df = neighborhood_df.groupby(['Neighborhood Name', 'variable'])['value'].mean().reset_index()\nwalk_scores = dict(zip(list(neighborhood_df[neighborhood_df.variable=='Walkability Score']['Neighborhood Name']),\n                       list(neighborhood_df[neighborhood_df.variable=='Walkability Score']['value'])\n                      ))\nneighborhood_df.loc[:, 'Walkability Score'] = neighborhood_df['Neighborhood Name'].map(walk_scores)\n\n# reformat to get the averages\nnation = nation[outcomes_cols+['households_w_vehicle']]\nnation.drop('households_no_vehicle_perc', axis='columns', inplace=True)\nnation_avg = pd.melt(nation,\n                     value_vars = [i for i in col_mapping.keys() if 'neighborhood_name' not in i])\nnation_avg = nation_avg.groupby('variable')['value'].mean().reset_index()\n\n# create cleaned column for plotting the national averages\nnation_avg['National Average'] = nation_avg['variable'].map(col_mapping)\n\n# create DC average walkability score\nneighborhood_df['dc_avg_walk'] = merged_df['Walkability Score'].mean()\n\n# add URL to the american flag icon\nnation_avg['flag_url'] = 'https://upload.wikimedia.org/wikipedia/commons/d/de/Flag_of_the_United_States.png'\n\n\n\"\"\"\nCREATE VISUALIZATION\n\"\"\"\n\n# define a click on the chloropleth map so that it can filter the bar chart\nclick = alt.selection_multi(fields=['Neighborhood Name'])\n\n# create the chloropleth map\nchoropleth = (alt.Chart(merged_df,\n                        title = \"Walkability of DC Census Tracts\"\n                       )\n              .mark_geoshape(stroke='white')\n              .transform_lookup(\n                                lookup='geoid_tract_20',\n                                from_=alt.LookupData(merged_df,\n                                                     'geoid_tract_20',\n                                                     ['Walkability Score', 'Neighborhood Name'])\n              ).encode(\n                    alt.Color('Walkability Score:Q',\n                              scale=alt.Scale(scheme='redyellowblue',\n                                              reverse=True\n                                             ),\n                              title = \"DC Walkability\"\n                             ),\n                    opacity=alt.condition(click,\n                                          alt.value(1),\n                                          alt.value(0.2)),\n                    tooltip=['Neighborhood Name:N', 'Walkability Score:Q'])\n              .add_selection(click)\n             )\n\nbars = (\n    alt.Chart(neighborhood_df,\n              title='Outcomes of DC Neighborhoods')\n    .mark_bar()\n    .encode(\n        x = alt.X('variable:N',\n                  axis=alt.Axis(labelAngle=-45)),\n        color = 'mean(Walkability Score):Q',\n        y = alt.Y('mean(value):Q',\n                  sort='x',\n                  scale = alt.Scale(domain = [0, 100])\n                 ),\n        tooltip = [\n                 'variable:N',\n                 'mean(value):Q'\n                ]\n    ).properties(\n        width = 200,\n        height = 300\n    ).transform_filter(click))\n\n# modify the axes and title labels\nbars.encoding.y.title = 'Avg. Value Across All Census Tracts'\nbars.encoding.x.title = 'Outcome'\n\nnation_avg_lines = (alt.Chart(nation_avg)\n                    .mark_tick(\n                        color=\"black\",\n                        thickness=3,\n                        size=39,  # controls width of tick\n                        strokeDash=[1,2]\n                    )\n                    .encode(\n                        x = 'National Average:N',\n                        y='value:Q'\n                    ))\n\nnation_avg_img = (alt.Chart(nation_avg)\n                    .mark_image(\n                        width=15,\n                        height=15)\n                    .encode(\n                        x='National Average:N',\n                        y='value:Q',\n                        url='flag_url',\n                        tooltip = ['National Average', 'value:Q']\n                    ))\n\n# plot the two graphs together\nalt.hconcat(choropleth, (bars+nation_avg_lines+nation_avg_img))\n\n\nC:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_1156\\2034273718.py:23: DtypeWarning:\n\nColumns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n\n\n\n\nFirst, we want to investigate whether walkability has an impact on other aspects of peoples’ lives. This visualization vies into the data science question of whether a more walkable neighborhood leads to higher socioeconomic outcomes. One of theories behind this data science question is that a more walkable neighborhood may result in closer proximity to higher paying job opportunities. Our second theory was that the designs of walkable neighborhoods often results in higher economic activity within that neighborhood due to increased foot traffic, which might generate more business within an area.\nThe left plot is a map of every census tract1 in the District of Columbia and the color of each census tract is encoded with that tract’s walkability score. Certain D.C. neighborhoods are comprised of several census tracts, depending on the population density of that neighborhood.2 Hovering over each census tract will display the name of the neighborhood that it is in, as well as the walkability score for that particular census tract. The right bar graph shows several social outcomes averaged across the entire district. If you click on a certain neighborhood (which may be comprised of more than one census tract) on the map, it will then highlight that neighborhood in the map, and then update the bar graph with the corresponding social outcomes averaged across just that neighborhood. On each bar, the national averages are also displayed, marked by the image of an American flag with a horizontal line indicator as well. Hovering over each bar gives you the value of that social outcome averaged across all the census tracts in that neighborhood, and hovering over each American flag gives you the national average of that social outcome.\nOverall, we can see that DC is a highly walkable city, especially in comparison to the rest of the United States. In fact, it has almost double the walkability score as the national average. Accompanying that fact, we see that far fewer households in DC have vehicles in comparison to the national average. Interestingly, we see that DC fares about average for the social outcomes reported on. We that the most walkable parts of the city are concentrated in the city center around downtown, and as one ventures out from the city center the walkability decreases. An interesting finding is that although all edges of the city decrease in walkability, we see that the topmost edges of the city (wards 3 and 4) increase in car ownership, have very low rates of poverty, and higher high school education attainment. The lower edges of the city (wards 7 and 8) have lower walkability scores but still have lower rates of car ownership, higher poverty, and lower high school degree attainment (in comparison with wards 3 and 4). This logically suggests that car ownership is a key factor in economic success in less walkabile areas. In contrast, we see that in highly walkable neighborhoods such as Logan Circle / Shaw, it has significantly lower car ownership even in comparison to the DC average, yet has lower rates of poverty, and higher rates of high school degree attainment .\n1 A census tract is a geographic region defined for the purpose of taking a census. There are 179 census tracts in Washington, D.C. 2 Census tracts generally have a population size between 1,200 and 8,000 people, with an optimum size of 4,000 people. A census tract usually covers a contiguous area; however, the spatial size of census tracts varies widely depending on the density of settlement."
  },
  {
    "objectID": "index.html#how-is-walkability-associated-with-health-outcomes-in-washington-d.c.",
    "href": "index.html#how-is-walkability-associated-with-health-outcomes-in-washington-d.c.",
    "title": "Walkability in D.C.",
    "section": "2. How is walkability associated with health outcomes in Washington, D.C.?",
    "text": "2. How is walkability associated with health outcomes in Washington, D.C.?\n\n\nCode\n# IMPORT RELEVANT LIBRARIES\nimport numpy as np\nimport pandas as pd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\nimport numpy as np\nimport json\nimport requests\nimport numpy as np\nimport scipy.stats\nimport plotly.subplots as sp\nfrom pathlib import Path\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# import the csv\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\nraw_data_dir = Path().absolute().parent.absolute().parent/\"data\"/\"raw_data\"\n\ndc_health_df = pd.read_csv(raw_data_dir/\"PLACES__Census_Tract_Data__GIS_Friendly_Format___2022_release (1).csv\")\n\n# filter for where StateAbbr = DC\ndc_health_df = dc_health_df[dc_health_df['StateAbbr'] == 'DC']\n\n# Resetting defaults and import plotly libraries\nimport plotly.io as pio\npio.renderers.default = \"browser\"\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport statsmodels.api as sm\nimport numpy as np\nfrom sklearn.metrics import r2_score\n\n# theming variables \n\n# choose the figure font\nfont_dict=dict(family='Arial',\n               size=14,\n               color='black'\n               )\n# isolate only columns with CrudePrev in the name\ndc_health_df_prev = dc_health_df.filter(regex='CrudePrev')\ndf = dc_health_df_prev\n\n# Rename columns\ndf = df.rename(columns={'ACCESS2_CrudePrev': '% of Adults without Health Insurance', \n                        'ARTHRITIS_CrudePrev': '% of Adults with Arthritis', \n                        'BINGE_CrudePrev': '% of Adults who Binge Drink',\n                        'BPHIGH_CrudePrev': '% of Adults with High Blood Pressure',\n                        'BPMED_CrudePrev': '% of Adults with High Blood Pressure who take Blood Pressure Medication',\n                        'CANCER_CrudePrev': '% of Adults who were Diagnosed with Cancer',\n                        'CASTHMA_CrudePrev': '% of Adults who were Diagnosed with Asthma',\n                        'CERVICAL_CrudePrev': '% of Women who had a Pap Smear in the Past 3 Years',\n                        'CHD_CrudePrev': '% of Adults who were Diagnosed with Coronary Heart Disease',\n                        'CHECKUP_CrudePrev': '% of Adults who had a Routine Checkup in the Past Year',\n                        'CHOLSCREEN_CrudePrev': '% of Adults who had Cholesterol Checked in the Past 5 Years',\n                        'COLON_SCREEN_CrudePrev': '% of Adults who had a Colonoscopy or similar test in the Past 10 Years',\n                        'COPD_CrudePrev': '% of Adults who were Diagnosed with COPD (Chronic Obstructive Pulmonary Disease)',\n                        'COREM_CrudePrev': '% Prevalence of Older Adult Men aged >=65 years who are up to date on preventative health',\n                        'COREW_CrudePrev': '% Prevalence of Older Adult Women aged >=65 years who are up to date on preventative health',\n                        'CSMOKING_CrudePrev': '% of Adults who Currently Smoke',\n                        'DENTAL_CrudePrev': '% of Adults who had a Dental Visit in the Past Year',\n                        'DEPRESSION_CrudePrev': '% of Adults who were Diagnosed with Depression',\n                        'DIABETES_CrudePrev': '% of Adults who were Diagnosed with Diabetes',\n                        'GHLTH_CrudePrev': '% of Adults who reported their Health as not Good',\n                        'HIGHCHOL_CrudePrev': '% of Adults who were Diagnosed with High Cholesterol',\n                        'KIDNEY_CrudePrev': '% of Adults who were Diagnosed with Kidney Disease',\n                        'LPA_CrudePrev': '% of Adults who are Physically Inactive', \n                        'MAMMOUSE_CrudePrev': '% Women aged 50-74 years who had a Mammogram in the Past 2 Years',\n                        'MHLTH_CrudePrev': '% of Adults who reported their Mental Health as not Good',\n                        'OBESITY_CrudePrev': '% of Adults who were Obese',\n                        'PHLTH_CrudePrev': '% of Adults who reported their Physical Health as not Good',\n                        'SLEEP_CrudePrev': '% of Adults who reported their Sleep as not Good',\n                        'STROKE_CrudePrev': '% of Adults who were Diagnosed with Stroke',\n                        'TEETHLOST_CrudePrev': '% of Adults who have lost all of their Natural Teeth'})\n\n# list of health metrics for drop down menu\ncolumn_names = df.columns\n\n# Creating the initial scatter plot\nfig = go.Figure(go.Scatter(x=df[column_names[0]], y=df[column_names[1]], mode='markers'))\n\n# Label axes\nfig.update_xaxes(title_text='X Axis')\nfig.update_yaxes(title_text='Y Axis')\n\n# Setting the range for x and y axes\nfig.update_xaxes(range=[0, 100])\nfig.update_yaxes(range=[0, 100])\n\nfor col in column_names:\n    for col2 in column_names:\n        x = df[col]\n        y = df[col2]\n        fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name=col + ' vs ' + col2, showlegend=False, visible=False))\n\n# Update the visibility of the traces\n        \n\ndef update_visibility(selected_col, selected_col2):\n    for i, trace in enumerate(fig.data):\n        if trace.name == selected_col + ' vs ' + selected_col2:\n            trace.visible = True\n        elif trace.name == selected_col + ' vs ' + selected_col2 + ' Best Fit':\n            trace.visible = True\n        else:\n            trace.visible = False\n\n# Create the drop-down menus for x (col) and y (col2) axes of the scatter plot\ncol_dropdown = [{'label': col, 'value': col} for col in column_names]\ncol2_dropdown = [{'label': col2, 'value': col2} for col2 in column_names]\n\n# #Define the dropdown menu for x-axis\nbutton_layer_1_height = 1.08\nx_axis_dropdown = go.layout.Updatemenu(\n    buttons=list([dict(args=[{'x': [df[col]]}, update_visibility(col, col2)], label=col, method='update') for col in column_names]),\n    direction=\"down\",\n    pad={\"r\": 10, \"t\": 10},\n    showactive=True,\n    x=0.06,\n    xanchor=\"left\",\n    y=button_layer_1_height + 0.05,\n    yanchor=\"top\"\n)\n\n\n\n# Define the dropdown menu for y-axis\ny_axis_dropdown = go.layout.Updatemenu(\n    buttons=list([dict(args=[{'y': [df[col2]]}, update_visibility(col, col2)], label=col2, method='update') for col2 in column_names]),\n    direction=\"down\",\n    pad={\"r\": 10, \"t\": 10},\n    showactive=True,\n    x=0.06,\n    xanchor=\"left\",\n    y=button_layer_1_height,\n    yanchor=\"top\"\n)\n\n\n\n\n# Update the layout to include the dropdown menus\nfig.update_layout(\n    updatemenus=[x_axis_dropdown, y_axis_dropdown],\n    font=font_dict,\n)\n\n\n# Label axes\nfig.update_xaxes(title_text='X Axis')\nfig.update_yaxes(title_text='Y Axis')\n\n# Setting the range for x and y axes\nfig.update_xaxes(range=[0, 100])\nfig.update_yaxes(range=[0, 100])\n\n# Update plot sizing\nfig.update_layout(\n    width=900,\n    height=900,\n    autosize=False,\n    #margin=dict(t=100, b=0, l=0, r=0),\n)\n\n# add annotations\nfig.update_layout(\n    annotations=[\n        dict(\n            text=\"X Axis:\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height + 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        ),\n        dict(\n            text=\"Y Axis:\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height - 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        )\n    ]\n)\n\n\n# Change background color to defined colors\nfig.update_layout(\n    plot_bgcolor='rgb(230, 230, 230)'\n)\n\n# Change scatter point color to defined colors\nfig.update_traces(\n    marker=dict(color='rgb(112, 14, 1)')\n)\n\n# # # Create a function to update the visibility of the traces based on selected columns\n# def update_visibility(selected_col, selected_col2):\n#     for i, trace in enumerate(fig.data):\n#         trace.visible = (trace.name == selected_col + ' vs ' + selected_col2)\n#         trace.visible = (trace.name == selected_col + ' vs ' + selected_col2 + ' Best Fit')\n\n# Display the scatter plot with dropdown menus\nfig.show()\n\n# Import walkability data\n\ndf_walk = pd.read_csv(raw_data_dir/\"joined_depression_cre_walkability.csv\")\ndc_health_df.rename(columns={'TractFIPS': 'census_tract'}, inplace=True)\ndf_walk.rename(columns={'geoid_tract_20': 'census_tract'}, inplace=True)\n# Merge the two dataframes\ndf_merged = pd.merge(dc_health_df, df_walk, on='census_tract', how='left')\n\n# Resetting defaults and import plotly libraries\nimport plotly.io as pio\npio.renderers.default = \"browser\"\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n# isolate only columns with CrudePrev in the name\ndc_health_df_prev = df_merged.filter(regex='CrudePrev')\n# add the walkability_score column back in\ndc_health_df_prev['walkability_score'] = df_merged['walkability_score']\ndf = dc_health_df_prev\n\n# Rename columns\ndf = df.rename(columns={'ACCESS2_CrudePrev': '% of Adults without Health Insurance', \n                        'ARTHRITIS_CrudePrev': '% of Adults with Arthritis', \n                        'BINGE_CrudePrev': '% of Adults who Binge Drink',\n                        'BPHIGH_CrudePrev': '% of Adults with High Blood Pressure',\n                        'BPMED_CrudePrev': '% of Adults with High Blood Pressure who take Blood Pressure Medication',\n                        'CANCER_CrudePrev': '% of Adults who were Diagnosed with Cancer',\n                        'CASTHMA_CrudePrev': '% of Adults who were Diagnosed with Asthma',\n                        'CERVICAL_CrudePrev': '% of Women who had a Pap Smear in the Past 3 Years',\n                        'CHD_CrudePrev': '% of Adults who were Diagnosed with Coronary Heart Disease',\n                        'CHECKUP_CrudePrev': '% of Adults who had a Routine Checkup in the Past Year',\n                        'CHOLSCREEN_CrudePrev': '% of Adults who had Cholesterol Checked in the Past 5 Years',\n                        'COLON_SCREEN_CrudePrev': '% of Adults who had a Colonoscopy or similar test in the Past 10 Years',\n                        'COPD_CrudePrev': '% of Adults who were Diagnosed with COPD (Chronic Obstructive Pulmonary Disease)',\n                        'COREM_CrudePrev': '% Prevalence of Older Adult Men aged >=65 years who are up to date on preventative health',\n                        'COREW_CrudePrev': '% Prevalence of Older Adult Women aged >=65 years who are up to date on preventative health',\n                        'CSMOKING_CrudePrev': '% of Adults who Currently Smoke',\n                        'DENTAL_CrudePrev': '% of Adults who had a Dental Visit in the Past Year',\n                        'DEPRESSION_CrudePrev': '% of Adults who were Diagnosed with Depression',\n                        'DIABETES_CrudePrev': '% of Adults who were Diagnosed with Diabetes',\n                        'GHLTH_CrudePrev': '% of Adults who reported their Health as not Good',\n                        'HIGHCHOL_CrudePrev': '% of Adults who were Diagnosed with High Cholesterol',\n                        'KIDNEY_CrudePrev': '% of Adults who were Diagnosed with Kidney Disease',\n                        'LPA_CrudePrev': '% of Adults who are Physically Inactive', \n                        'MAMMOUSE_CrudePrev': '% Women aged 50-74 years who had a Mammogram in the Past 2 Years',\n                        'MHLTH_CrudePrev': '% of Adults who reported their Mental Health as not Good',\n                        'OBESITY_CrudePrev': '% of Adults who were Obese',\n                        'PHLTH_CrudePrev': '% of Adults who reported their Physical Health as not Good',\n                        'SLEEP_CrudePrev': '% of Adults who reported their Sleep as not Good',\n                        'STROKE_CrudePrev': '% of Adults who were Diagnosed with Stroke',\n                        'TEETHLOST_CrudePrev': '% of Adults who have lost all of their Natural Teeth'})\n\n# list of health metrics for drop down menu\ncolumn_names = df.columns\n\n# Creating the initial scatter plot\nfig = go.Figure(go.Scatter(x=df[column_names[0]], y=df[column_names[1]], mode='markers'))\n\n# Label axes\nfig.update_xaxes(title_text='Walkability Score')\nfig.update_yaxes(title_text='Y Axis')\n\n# Setting the range for x and y axes\n#fig.update_xaxes(range=[0, 100])\nfig.update_xaxes(range=[0, max(df['walkability_score'])])\nfig.update_yaxes(range=[0, 100])\n\nfor col in column_names:\n    fig.add_trace(go.Scatter(x=df['walkability_score'], y=df[col], mode='markers', name='Walkability vs ' + col, visible=False))\n\n\ndef update_visibility(selected_col, selected_col2):\n    return [(trace.name == selected_col + ' vs ' + selected_col2) for trace in fig.data]\n\n\n# Create the drop-down menus for x (col) and y (col2) axes of the scatter plot\ncol_dropdown = [{'label': col, 'value': col} for col in column_names]\n\n# Define the dropdown menu for x-axis\nbutton_layer_1_height = 1.08\n\ny_axis_dropdown = go.layout.Updatemenu(\n    buttons=list([\n        dict(\n            args=[\n                {\"y\": [df[col]], \"visible\": [(trace.name == \"Walkability vs \" + col) for trace in fig.data]}\n            ],\n            label=col,\n            method=\"update\",\n        ) for col in column_names\n    ]),\n    direction=\"down\",\n    pad={\"r\": 10, \"t\": 10},\n    showactive=True,\n    x=0.06,\n    xanchor=\"left\",\n    y=button_layer_1_height,\n    yanchor=\"top\"\n)\n\n\n\n\n# Update the layout to include the dropdown menus\nfig.update_layout(\n    updatemenus=[y_axis_dropdown],\n    font=font_dict\n)\n\n# Label axes\nfig.update_xaxes(title_text='X Axis')\nfig.update_yaxes(title_text='Y Axis')\n\n\n\n# Update plot sizing\nfig.update_layout(\n    width=900,\n    height=900,\n    autosize=False,\n    #margin=dict(t=100, b=0, l=0, r=0),\n)\n\n# add annotations\nfig.update_layout(\n    annotations=[\n        dict(\n            text=\"X Axis: Walkability Score of the Neighborhood\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height + 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        ),\n        dict(\n            text=\"Y Axis:\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height - 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        )\n    ]\n)\n\n\ndef update_visibility(selected_col, selected_col2):\n    return [(trace.name == selected_col + ' vs ' + selected_col2) for trace in fig.data]\n\n\n# Change background color to grey\nfig.update_layout(\n    plot_bgcolor='rgb(230, 230, 230)'\n)\n\n\n# Change scatter point color to red\nfig.update_traces(\n    marker=dict(color='rgb(112, 14, 1)')\n)\n\n# Display the scatter plot with dropdown menus\nfig.show()\n\n\n\n                                                \n\n\nC:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_1156\\3039330416.py:235: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n                                                \n\n\nAfter examining the relationship between walkability and socioeconomic outcomes, we wanted to investigate the relationship between walkability and health outcomes as well. In the graph above, we can see that on the x-axis we have walkability score and on the y-axis we have the selected health metric. The data is presented at the neighborhood level; in other words, each data point on the scatter plot represents a neighborhood in Washington, D.C. as defined by U.S. Census Tract data.\nUpon exploring the different health metrics, we can see that neighborhoods with low walkability fare worse at many health metrics, such as percentage of adults who lost all their adult teeth and percentage of adults who are physically inactive. This makes sense because lower walkability makes it harder to be physically active. In addition, oral health is correlated to diverse health outcomes including oral health. However, there are interactions between health outcomes, such as the impact of poor oral health on physical activity, that might not point to a straightforward causal relationship between walkability and a particular health outcome.3 We can reference the first graph that shows the relationship between pairs of health metrics to understand interactions between health metrics more."
  },
  {
    "objectID": "index.html#how-accessible-are-neighborhoods-in-washington-d.c.-by-bike",
    "href": "index.html#how-accessible-are-neighborhoods-in-washington-d.c.-by-bike",
    "title": "Walkability in D.C.",
    "section": "3. How accessible are neighborhoods in Washington, D.C. by bike?",
    "text": "3. How accessible are neighborhoods in Washington, D.C. by bike?\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nimport plotly.graph_objects as go\nfrom vega_datasets import data\nimport requests\nimport json\nimport warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\nraw_data_dir = Path().absolute().parent.absolute().parent/\"data\"/\"raw_data\"\n\nbikeshare_df = pd.read_csv(Path().absolute().parent.absolute().parent/\"data/cleaned_data/bikeshare_cleaned.csv\")\n# Create list of bikeshare stations outside of DC\nnondc_stations = [\n    32256,32251,32237,32241,32210,32225,32259,32223,32209,32240,32239,32245,32220,32214,32219,\n    32224,32217,32213,32239,32246,32247,32250,32248,32246,32228,32215,32238,32252,32249,32260,\n    32234,32231,32235,32255,32200,32208,32201,32211,32227,32207,32229,32221,32206,32233,32205,\n    32204,32205,32203,32206,32222,32230,32232,32600,32602,32603,32608,32605,32604,32607,32609,\n    31948,31904,32606,32601,31921,31905,31902,31901,31976,31036,31977,31900,31920,31049,31037,\n    31926,31919,31035,31973,31069,31023,31022,31021,31019,31020,31094,31092,31079,31030,31029,\n    31080,31093,31014,31062,31077,31073,31024,31040,31028,31017,31924,31027,31947,31066,31075,\n    31949,31053,31971,31067,31058,31923,31063,31068,31951,31945,31095,31006,31005,31091,31004,\n    31936,31071,31090,31950,31064,31935,31011,31012,31009,31944,31052,31010,31959,31916,31088,\n    31960,31956,31910,31083,31915,31087,31085,31913,31915,31970,31969,31906,31098,31048,31081,\n    31084,31082,31974,31930,31932,31953,31942,31967,32406,32423,32415,32407,32405,32401,32400,\n    32405,32404,32413,32418,32410,32403,32408,32421,32402,32417,32422,32420,32414,32412,32416,\n    32059,32061,32026,32011,32049,32082,32058,32025,32001,32058,32082,32024,32043,32036,32012,\n    32034,32035,32050,32056,32426,32425,32424,32426,32085,32094,32089,32093,32091,32090,32087,\n    32088,32086,32092,32022,32066,32064,32062,32065,32073,32063,32084,32054,32051,32040,32046,\n    32029,32055,32002,32021,32003,32048,32013,32000,32008,32028,32027,32053,32039,32057,32078,\n    32075,32077,32076,32079,32080,32074,32081,32032,32047,32044,32017,32007,32009,32023,32033,\n    32016,32004,32005,32072,32041,32052,32071,32038,32037,32045,32067,32069,32068,32018,32253,\n    32236,32243,32258,32216,32212,32218,32019,32411,31929,31914,31907,31903,31958,31933,31041,\n    31042,31968,31044,31045,31955,31046,31047,31099,31043,31097,31931,31918,31086,31927,31966,\n    21943,31963,31952,31964,31962,31908,31072,31941,31961,31928,31054,31033,31059,31057,31061,\n    31056,31055,31909,31912,31065,31032,31074,31078,32419,31957,31954,31946,31972,31060,31938,\n    31013,31002,31007,31000,31003,31096,31070,31039,31034,31025,31038,31026,31050,31940,31089,\n    31031,31051,31937,31016,31018,31039,31015,31917,31076,31939,32409\n]\nalt.data_transformers.enable('default',max_rows=None)\n#### BACKGROUND FOR DC MAP \n# Define background of Washington D.C.\nresponse1 = requests.get('https://raw.githubusercontent.com/arcee123/GIS_GEOJSON_CENSUS_TRACTS/master/11.geojson')\nbackground = alt.Chart(alt.Data(values=response1.json()), title= \"Map of D.C. Bike Lanes, Capital Bikeshare Stations, & Routes in March 2023\").mark_geoshape(\n        fill=\"lightgray\",\n        stroke='white',\n        strokeWidth=1\n    ).encode(\n    ).properties(\n        width=600,\n        height=600\n    )\n#### BACKGROUND FOR DC BIKE LANE LOCATIONS \n# Open GeoJSON file for bicycle lanes\nwith open(raw_data_dir/'Bicycle_Lanes.geojson') as f:\n    data = json.load(f)\n# Create background of D.C.\nbackground_lanes = alt.Chart(alt.Data(values=data)).mark_geoshape(\n        stroke='#d6a320',\n        strokeWidth=1\n        ).properties(\n        width=600,\n        height=600\n    )\n#### MOUSEOVER SELECTION\n# Create mouseover selection\nselect_station = alt.selection_single(\n    on=\"mouseover\", nearest=True, fields=[\"start_station_name\"], empty='none'\n)\n#### NETWORK CONNECTIONS FOR MAP \n# Filter non-DC stations\ntmp1 = bikeshare_df[~bikeshare_df['start_station_id'].isin(nondc_stations)]\ntmp1 = tmp1[~tmp1['end_station_id'].isin(nondc_stations)]\n# Keep only relevant columns and drop duplicates to have one row per route\ntmp1 = tmp1[['start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng']].drop_duplicates()\n# Define connections\nconnections = alt.Chart(tmp1).mark_rule(opacity=0.35).encode(\n    latitude=\"start_lat:Q\",\n    longitude=\"start_lng:Q\",\n    latitude2=\"end_lat:Q\",\n    longitude2=\"end_lng:Q\"\n).transform_filter(\n    select_station\n)\n#### POINTS FOR MAP \n# Filter non-DC stations\ntmp2 = bikeshare_df[~bikeshare_df['start_station_id'].isin(nondc_stations)]\ntmp2 = tmp2[~tmp2['end_station_id'].isin(nondc_stations)]\n# Create boolean columns for rideable type and membet type\ntmp2['classic_bike'] = np.where(tmp2['rideable_type'] == 'classic_bike', 1, 0)\ntmp2['electric_bike'] = np.where(tmp2['rideable_type'] == 'electric_bike', 1, 0)\ntmp2['docked_bike'] = np.where(tmp2['rideable_type'] == 'docked_bike', 1, 0)\n# Temporary dataframe showing unique station locations with ride count\ntmp2 = tmp2[['start_station_name','start_station_id', 'start_lng', 'start_lat', 'ride_id', 'classic_bike', 'electric_bike', 'docked_bike']].groupby(['start_station_name', 'start_station_id','start_lng', 'start_lat']).agg({'ride_id': 'count', 'classic_bike': 'sum', 'electric_bike':'sum', 'docked_bike':'sum'}).reset_index()\ntmp2.rename(columns= {'ride_id':'count_rides', 'classic_bike': 'count_classic', 'electric_bike': 'count_electric', 'docked_bike': 'count_dock'}, inplace = True)\ntmp2['color'] = 'Bike Station'\npoints = alt.Chart(tmp2).mark_circle().encode(\n    latitude=\"start_lat:Q\",\n    longitude=\"start_lng:Q\",\n    color = alt.Color('color:N', title = \"Legend\", scale = alt.Scale(domain=['Bike Station', 'Bike Lane'],range=['#962e2ec8', '#d6a320'])),\n    size=alt.Size(\"count_rides:Q\", scale=alt.Scale(range=[15, 250]), legend=None),\n    order=alt.Order(\"count_rides:Q\", sort=\"descending\"),\n    tooltip=[\n             alt.Tooltip('start_station_id:Q', title='\\U0001f4cd Start Station ID'),\n             alt.Tooltip('start_station_name:N', title='\\U0001f6e3 Start Station Name'),\n             alt.Tooltip('count_rides:Q', title='\\U0001f50d Ride Count'),\n             alt.Tooltip('count_classic:Q', title='\\U0001f6b4 Classic Bike Count'),\n             alt.Tooltip('count_electric:Q', title='\\U0001f6b5 Electric Bike Count'),\n             alt.Tooltip('count_dock:Q', title='\\U0001f6b2 Docked Bike Count')\n             ]\n).add_selection(\n    select_station\n)\nalt.themes.enable('vox')  # add theme\n# Show visualization\n(background + background_lanes + connections + points).configure_view(stroke=None)\n\n\n\n\n\n\n\ninnovative plot\nFollowing our exploration of the relationship between a neighborhood’s walkability score and its socioeconomic and health outcomes, we wanted to explore another dimension of walkability - ease of access of bikes. To do this, we explored the distribution of Capital Bikeshare stations and bike lanes across Washington, D.C..\nCapital Bikeshare is a bikeshare system that services the D.C. metro area in collaboration with the D.C. government and surrounding jurisdictions (e.g., Arlington VA, Alexandria VA, Montgomery County MD, etc.). It launched in 2010 and has since expanded to have over 600 stations and 5,000 bikes. Bikes from the network are docked at the various stations and can be used by anyone in the city at any time for a low cost4. Capital Bikeshare is one of the largest bikesharing systems in the country and contributes to the D.C. Government Department of Transportation’s commitment to improve bicycle access throughout the city, reduce car dependency, and encourage bicycle use for work, tourism, and more5. Bike lanes throughout the city are equally important because they allow bicyclists to safely travel on bike throughout the city. Each year, on average, there are approximately 265 bicycle crashes reported in the D.C.6. To increase public safety on bikes, the city has created over 100 miles of bike lanes since 2001 and has committed to building 20 additional miles by 20237. Since bike lanes and the Capital Bikeshare program are two major initiatives for improving quality of life and transportation access in D.C., our team decided to analyze data from both programs together. We created the following questions to help guide our development of a visual plot:\n\nWhere are the Capital Bikeshare stations and bike lanes located? Are they concentrated in any area in particular?\nWhat Capital Bikeshare stations are the most popular? Which ones are the least popular?\nWhat are some improvements the city can make to make Capital Bikeshare more accessible to inidviduals of all socio-economic backgrounds?\nWhere should the city make new bike lanes?\n\nAt first glance, it becomes apparent that the majority of Capital Bikeshare stations are concentrated near downtown. As a result, the size of these stations are larger, which indicates more trips are done from these stations. Similarly, majority of the bike lanes are located mostly in downtown and follow streets that lead toward downtown. The suburb areas within D.C., such as Tenleytown, Cleveland Park, Takoma Park, and Anacostia tend to have sparse bike share stations and even less bike lanes.\nThe trends highlighted by our visual plot indicate that the D.C. Department of Transportation prioritized getting to and from the downtown area when creating bikeshare stations and bike lanes. While this is ideal for tourists spending a day in downtown or commuters getting to work in downtown, there are some limitations with this architecture. First, the lack of stations and bike lanes outside of downtown means that individuals outside of downtown have less access to transit via bicycles. This means that individuals have to rely mostly on cars, which may be unaffordable to those with lower incomes, or public transit (e.g., bus or metro). Additionally, individuals looking to travel from suburb neighborhood to suburb neighborhood (i.e., not travel to downtown) are not able to safely do it via bike. This is evident in our visualization when a user highlights over any station and sees that the routes almost always lead toward stations in downtown and hardly ever lead to neighboring areas. If a person wants to bike from Tenleytown to Takoma, for instance, there are no bike lanes across surrounding neighborhoods to safely do this.\nOur visualization highlights that while D.C. has come a long way in providing bikeshare and bike lane access, improvements can be made by creating bike stations and bike lanes across adjacent neighborhoods. With these improvements, individuals from all backgrounds looking to enjoy what D.C. has to offer outside of just downtown will one day be able to this with a bike!"
  },
  {
    "objectID": "index.html#what-is-public-sentiment-around-walkability-in-washington-d.c.",
    "href": "index.html#what-is-public-sentiment-around-walkability-in-washington-d.c.",
    "title": "Walkability in D.C.",
    "section": "5. What is public sentiment around walkability in Washington, D.C.?",
    "text": "5. What is public sentiment around walkability in Washington, D.C.?\nFollowing the above analysis, we wanted to gauge public sentiment around walkability in Washington, D.C. to see if that sheds light on our quantitative findings. We first want to observe the most frequent words across categories. Sentiment analysis of user comments is a crucial tool for comprehending socially relevant issues like transportation and walkability of cities, which can help guide decisions that improve the quality of life for locals, workers, and visitors alike. By analyzing the sentiment of user opinions, we can gain a deeper understanding of how people feel about these factors and how they impact their ability and willingness to transit in a particular city. For instance, sentiment analysis can show whether people feel safe walking through particular neighborhoods or whether they find it simple to get to bike lanes or public transportation. Additionally, sentiment analysis can be used to find neighborhoods that are more walkable for particular groups of people or where certain amenities are lacking, as well as places where there are disparities in walkability. Cities can work to build more equitable and inclusive communities by addressing these disparities. In this work we gathered reddit user’s opinions for different transportation and walkability topics in D.C. the topics are related to vehicles, bicycle and walkability.\nWe first want to observe the most frequent words across categories.\nBicycle Wordcloud:\n\n\n\nCode\nd3 = require(\"d3@7\")\nd3Cloud = require(\"d3-cloud@1\")\nimport {howto} from \"@d3/example-components\"\n\nfunction WordCloud(title,text, {\n  size = group => group.length, // Given a grouping of words, returns the size factor for that word\n  word = d => d, // Given an item of the data array, returns the word\n  marginTop = 0, // top margin, in pixels\n  marginRight = 0, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 0, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  maxWords = 250, // maximum number of words to extract from the text\n  fontFamily = \"sans-serif\", // font family\n  fontScale = 30, // base font size\n  padding = 0, // amount of padding between the words (in pixels)\n  rotate = 0, // a constant or function to rotate the words\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  const words = typeof text === \"string\" ? text.split(/\\W+/g) : Array.from(text);\n  \n  const data = d3.rollups(words, size, w => w)\n    .sort(([, a], [, b]) => d3.descending(a, b))\n    .slice(0, maxWords)\n    .map(([key, size]) => ({text: word(key), size}));\n  \n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, 0, width, height])\n      .attr(\"width\", width)\n      .attr(\"font-family\", fontFamily)\n      .attr(\"text-anchor\", \"middle\")\n      .attr(\"fill\", \"#962e2ec8\") \n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n      .text(title);\n\n  const g = svg.append(\"g\").attr(\"transform\", `translate(${marginLeft},${marginTop})`);\n\n  const cloud = d3Cloud()\n      .size([width - marginLeft - marginRight, height - marginTop - marginBottom])\n      .words(data)\n      .padding(padding)\n      .rotate(rotate)\n      .font(fontFamily)\n      .fontSize(d => Math.sqrt(d.size) * fontScale)\n      .on(\"word\", ({size, x, y, rotate, text}) => {\n        g.append(\"text\")\n            .attr(\"font-size\", size)\n            .attr(\"transform\", `translate(${x},${y}) rotate(${rotate})`)\n            .text(text);\n      });\n\n  cloud.start();\n  invalidation && invalidation.then(() => cloud.stop());\n  return svg.node();\n}\nWordCloud(\"Bicycle\",\"bike bike bike bike bike bike bike bike bike bike bike bike bike get get get get get get one one one one lanes lanes lanes lanes good good good good trail trail trail trail st st st lane lane lane park park park like like like street street street city city mbt mbt bikes bikes many many ride ride trails trails way way pretty pretty people people th th go go rock rock creek creek nw nw map map take take lock lock want want much much\", {\n  width: 250,\n  height: 100,\n  size: () => .3 + Math.random(),\n  rotate: () => (~~(Math.random() * 6) - 3) * 30\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCar Wordcloud\n\n\nCode\nWordCloud(\"Car\",\"metro metro metro metro metro metro metro car car car car car car traffic traffic traffic traffic traffic speed speed speed speed speed people people people people people drive drive drive drive like like like like get get get get city city city driving driving driving time time time one one think think go go tickets tickets cameras cameras live live cars cars bike bike need need even even use use drivers drivers every every day day work work take take camera camera make make limit limit\", {\n  width: 250,\n  height: 100,\n  size: () => .3 + Math.random(),\n  rotate: () => (~~(Math.random() * 6) - 3) * 30\n})\n\n\n\n\n\n\n\n\n\nWalk Wordcloud\n\n\nCode\nWordCloud(\"Walk\",\"people people people people people people people people people city city city city city city city city like like like like like like like car car car car car get get get get live live live one one one much much much think think think philly philly philly really really really lot lot metro metro love love cars cars time time even even many many cities cities better better good good great great thats thats way way go go years years place place want want things things lived lived\", {\n  width: 250,\n  height: 100,\n  size: () => .3 + Math.random(),\n  rotate: () => (~~(Math.random() * 6) - 3) * 30\n})\n\n\n\n\n\n\n\n\nFrom this information we can see the word “metro” as a transportation method being mentioned while commenting on cars, to have a better understanding of the opinions we predicted the sentiment as “positive” “negative” or “neutral.\nBy analyzing the sentiment of each category we can see bike’s polarity median is higher than walk and car. Walk median and values are closer to the neutral value of 0 although its Q3 value is slightly up in the positive range. On the other hand the car category is below the neutral point having it’s median in -.26 and its Q3 value is closer to the median meaning most comments are under the neutral range and some are closer to it. Interestingly, all values are ranging from -1 to 1, which means that there are fully positive and negative comments across all categories.\n\n\nCode\nimport pandas as pd\nimport re\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport tensorflow as tf\nimport pandas as pd\nimport random\nimport numpy as np\nimport torch as torch\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport json\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n#opening previously modified sentiment analysis\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\nraw_data_dir = Path().absolute().parent.absolute().parent/\"data\"/\"raw_data\"\n\nb_sent = pd.read_csv(raw_data_dir/\"bikes_sent.csv\")\nc_sent = pd.read_csv(raw_data_dir/\"cars_sent.csv\")\nw_sent = pd.read_csv(raw_data_dir/\"walk_sent.csv\")\n\n# drop index\nb_sent = b_sent.drop(columns=['Unnamed: 0'])\nc_sent = c_sent.drop(columns=['Unnamed: 0'])\nw_sent = w_sent.drop(columns=['Unnamed: 0'])\n\n# add category\nb_sent[\"category\"] = \"bike\"\nc_sent[\"category\"] = \"car\"\nw_sent[\"category\"] = \"walk\"\n\nb_sent = b_sent.rename(columns={\"bikes\": \"text\"})\nc_sent = c_sent.rename(columns={\"cars\": \"text\"})\nw_sent = w_sent.rename(columns={\"walk\": \"text\"})\n\n#generate a single dataframe\ndf_sent = b_sent.append([c_sent,w_sent], ignore_index = True)\n\n#obtain polarity as a range of negative, neutral and positives\npolarity = []\nfor i in range(len(df_sent[\"label\"])):\n    if df_sent[\"POS\"][i] > df_sent[\"NEG\"][i]:\n        polarity.append(df_sent[\"POS\"][i])\n    elif df_sent[\"POS\"][i] < df_sent[\"NEG\"][i]:\n        polarity.append(df_sent[\"NEG\"][i]*-1)\n\ndf_sent[\"polarity\"] = polarity\n\ny0 = df_sent.loc[df_sent['category'] == 'bike']['polarity']\ny1 = df_sent.loc[df_sent['category'] == 'walk']['polarity']\ny2 = df_sent.loc[df_sent['category'] == 'car']['polarity']\n\ntrace0 = go.Box(\n    y=y0,\n    name = 'bike',\n    marker = dict(\n        color = 'rgba(148, 46, 46, 0.784)',\n    ),\n    notched=True\n)\ntrace1 = go.Box(\n    y=y1,\n    name = 'walk',\n    marker = dict(\n        color = 'rgb(153, 91, 40)',\n    ),\n    notched=True\n)\ntrace2 = go.Box(\n    y=y2,\n    name = 'car',\n    marker = dict(\n        color = 'rgb(214, 163, 32)',\n    ),\n    notched=True\n)\n\ndata = [trace0, trace1, trace2]\nlayout = go.Layout(\n    title = \"Sentiment polarity boxplot by category\"\n)\n\nfig = go.Figure(data=data,layout=layout)\nfont_dict=dict(family='Arial',\n               size=14,\n               color='black'\n               )\nfig.update_layout(font=font_dict)\n\nfig.update_layout(\n    plot_bgcolor='rgb(230, 230, 230)'\n)\n\niplot(fig, filename = \"Sentiment polarity boxplot by category\")\n\n\n\n                                                \n\n\n\n\nCode\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ntrace1 = go.Scatter(\n    x=df_sent['polarity'], y=df_sent['category'], mode='markers', name='points',\n    marker=dict(color='rgb(102,0,0)', size=2, opacity=0.4)\n)\ntrace2 = go.Histogram2dContour(\n    x=df_sent['polarity'], y=df_sent['category'], name='density', ncontours=30,\n    colorscale='Hot', reversescale=True, showscale=False,\n    hovertemplate='<br>Polarity: %{x}<br>Category: %{y}<br>Comments: %{z}'\n)\ntrace3 = go.Histogram(\n    x=df_sent['polarity'], name='Polarity',\n    marker=dict(color='rgb(214, 163, 32)'),\n    yaxis='y2',\n    hovertemplate='<br>%{x}<br>'\n)\ntrace4 = go.Histogram(\n    y=df_sent['category'], name='Category', marker=dict(color='rgba(148, 46, 46, 0.784)'),\n    xaxis='x2'\n)\ndata = [trace1, trace2, trace3, trace4]\n\nlayout = go.Layout(\n    showlegend=False,\n    autosize=False,\n    width=800,\n    height=750,\n    xaxis=dict(\n        domain=[0, 0.85],\n        showgrid=False,\n        zeroline=False\n    ),\n    yaxis=dict(\n        domain=[0, 0.85],\n        showgrid=False,\n        zeroline=False\n    ),\n    margin=dict(\n        t=50\n    ),\n    hovermode='closest',\n    bargap=0,\n    xaxis2=dict(\n        domain=[0.85, 1],\n        showgrid=False,\n        zeroline=False\n    ),\n    yaxis2=dict(\n        domain=[0.85, 1],\n        showgrid=False,\n        zeroline=False\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\nfont_dict=dict(family='Arial',\n               color='black'\n               )\nfig.update_layout(font=font_dict)\n\nfig.update_layout(yaxis_title=\"Category\",xaxis_title=\"Polarity\", title=\"Sentiment polarity of posts by category\") \n\niplot(fig, filename='2dhistogram-2d-density-plot-subplots')\n\n\n\n                                                \n\n\nDue to the uneven number of comments about walking in comparison to the other categories, the density plot and histograms provide more meaningful insight into trends. In the “walk” category, we observe that there is a high concentration of comments (382) in the highest positive polarity section. This is intriguing because even though the walk category gas a huge number of comments in the neutral range, most of the comments are concentrated in the most positive section. It is also interesting to note the density of neutral-negative and fully negative values in the same category. It is important to note that we gathered threads that were related to that category, so having negative comments does not necessarily mean a negative opinion towards the category itself. For example a user saying “I hate that the walkability in D.C. is almost null” is very different from “I hate walkability”, though both lines contain the negative words “hate” and “walkability”.\nOn the other hand, we see a low density of positive opinions for cars, and almost no comments in the neutral-positve range. From the histogram plot at the right we can observe that although the bike category has the smallest number of opinons we can see that it has more positive comments than cars.\nFinally, to better represent the observed sentiments we will observe the most frequent pair of words by category in the bigrams below. One of the biggest trends among these bigrams are the pair of words for referring to popular spaces in D.C. such as Florida Avenue, Adams Morgan, Columbia Heights. The frequencies at which these pairs appear by category are interesting: bike bigrams focus on specific avenues and intersections, such as blocks and avenues; the car category has frequent mentions of suburbs such as Maryland and Virginia; and the walk category has frequent mentions of parks, museums and monuments related to positive adjectives such as beautiful. The findings in this analysis highlight the relationship between driving towards suburbs in D.C. and walking/biking towards more touristic places. On the other hand, negative bigrams, such as “pedestrian death” and “rush hour traffic camera,” should be considered as repetitive words in the comments, along with other serious opinions like “traffic safety.” The walkability category also contains negative bigrams like “sucks” and “unsafe,” as well as combinations like “better infrastructure,” “poor person,” and “homeless people,” which require attention.\n\n\n\nCode\nchart = {\n  const links = data.links.map(d => Object.create(d));\n  const nodes = data.nodes.map(d => Object.create(d));\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", d3.forceLink(links).id(d => d.id).distance(40))\n      .force(\"charge\", d3.forceManyBody().strength(-40))\n      .force('collision', d3.forceCollide().radius(10))\n      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n\n  const svg = d3.select(DOM.svg(width, height));\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke-opacity\", 0.2)\n    .selectAll(\"path\")\n    .data(links)\n    .join(\"path\")\n      .attr(\"stroke-width\", 2)\n      .attr(\"stroke\", color)\n      .attr(\"fill\", \"transparent\");\n\n  const node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 0)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", 6)\n      .attr(\"fill\", \"#555\")\n      .call(drag(simulation))\n  \n  const textElements = svg.append('g')\n    .selectAll('text')\n    .data(nodes)\n    .enter().append('text')\n      .text(node => node.id)\n      .attr('font-size', 10)\n      .attr(\"font-family\", \"Helvetica\")\n      .attr(\"fill\", \"#555\")\n      .attr('dx', 10)\n      .attr('dy', 4)\n\n  simulation.on(\"tick\", () => {\n    link\n      .attr(\"d\", function(d) {\n      var dx = d.target.x - d.source.x,\n          dy = d.target.y - d.source.y,\n          dr = Math.sqrt(dx * dx + dy * dy);\n      return \"M\" + d.source.x + \",\" + d.source.y + \"A\" + dr + \",\" + dr + \" 0 0,1 \" + d.target.x + \",\" + d.target.y;\n  });\n    \n    textElements\n        .attr(\"x\", node => node.x)\n        .attr(\"y\", node => node.y)\n    \n    node\n        .attr(\"cx\", d => d.x)\n        .attr(\"cy\", d => d.y);\n  });\n\n  invalidation.then(() => simulation.stop());\n  \n  return svg.node();\n}\ndata = FileAttachment(\"../../data/cleaned_data/bigrams_bikes.json\").json()\n\nheight = 600\ncolor = {\n  const scale = d3.scaleOrdinal(d3.schemeSet1);\n  return d => scale(d.group);\n}\ndrag = simulation => {\n  \n  function dragstarted(d) {\n    if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n    d.fx = d.x;\n    d.fy = d.y;\n  }\n  \n  function dragged(d) {\n    d.fx = d3.event.x;\n    d.fy = d3.event.y;\n  }\n  \n  function dragended(d) {\n    if (!d3.event.active) simulation.alphaTarget(0);\n    d.fx = null;\n    d.fy = null;\n  }\n  \n  return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nchart_2 = {\n  const links = data_2.links.map(d => Object.create(d));\n  const nodes = data_2.nodes.map(d => Object.create(d));\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", d3.forceLink(links).id(d => d.id).distance(30))\n      .force(\"charge\", d3.forceManyBody().strength(-30))\n      .force('collision', d3.forceCollide().radius(10))\n      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n\n  const svg = d3.select(DOM.svg(width, height));\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke-opacity\", 0.2)\n    .selectAll(\"path\")\n    .data(links)\n    .join(\"path\")\n      .attr(\"stroke-width\", 2)\n      .attr(\"stroke\", color)\n      .attr(\"fill\", \"transparent\");\n\n  const node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 0)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", 6)\n      .attr(\"fill\", \"#555\")\n      .call(drag(simulation))\n  \n  const textElements = svg.append('g')\n    .selectAll('text')\n    .data(nodes)\n    .enter().append('text')\n      .text(node => node.id)\n      .attr('font-size', 10)\n      .attr(\"font-family\", \"Helvetica\")\n      .attr(\"fill\", \"#555\")\n      .attr('dx', 10)\n      .attr('dy', 4)\n\n  simulation.on(\"tick\", () => {\n    link\n      .attr(\"d\", function(d) {\n      var dx = d.target.x - d.source.x,\n          dy = d.target.y - d.source.y,\n          dr = Math.sqrt(dx * dx + dy * dy);\n      return \"M\" + d.source.x + \",\" + d.source.y + \"A\" + dr + \",\" + dr + \" 0 0,1 \" + d.target.x + \",\" + d.target.y;\n  });\n    \n    textElements\n        .attr(\"x\", node => node.x)\n        .attr(\"y\", node => node.y)\n    \n    node\n        .attr(\"cx\", d => d.x)\n        .attr(\"cy\", d => d.y);\n  });\n\n  invalidation.then(() => simulation.stop());\n  \n  return svg.node();\n}\ndata_2 = FileAttachment(\"../../data/cleaned_data/bigrams_cars.json\").json()\n\ndrag_2 = simulation => {\n  \n  function dragstarted(d) {\n    if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n    d.fx = d.x;\n    d.fy = d.y;\n  }\n  \n  function dragged(d) {\n    d.fx = d3.event.x;\n    d.fy = d3.event.y;\n  }\n  \n  function dragended(d) {\n    if (!d3.event.active) simulation.alphaTarget(0);\n    d.fx = null;\n    d.fy = null;\n  }\n  \n  return d3.drag_2()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nchart_3 = {\n  const links = data_3.links.map(d => Object.create(d));\n  const nodes = data_3.nodes.map(d => Object.create(d));\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", d3.forceLink(links).id(d => d.id).distance(40))\n      .force(\"charge\", d3.forceManyBody().strength(-40))\n      .force('collision', d3.forceCollide().radius(10))\n      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n\n  const svg = d3.select(DOM.svg(width, height));\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke-opacity\", 0.2)\n    .selectAll(\"path\")\n    .data(links)\n    .join(\"path\")\n      .attr(\"stroke-width\", 2)\n      .attr(\"stroke\", color)\n      .attr(\"fill\", \"transparent\");\n\n  const node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 0)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", 6)\n      .attr(\"fill\", \"#555\")\n      .call(drag(simulation))\n  \n  const textElements = svg.append('g')\n    .selectAll('text')\n    .data(nodes)\n    .enter().append('text')\n      .text(node => node.id)\n      .attr('font-size', 10)\n      .attr(\"font-family\", \"Helvetica\")\n      .attr(\"fill\", \"#555\")\n      .attr('dx', 10)\n      .attr('dy', 4)\n\n  simulation.on(\"tick\", () => {\n    link\n      .attr(\"d\", function(d) {\n      var dx = d.target.x - d.source.x,\n          dy = d.target.y - d.source.y,\n          dr = Math.sqrt(dx * dx + dy * dy);\n      return \"M\" + d.source.x + \",\" + d.source.y + \"A\" + dr + \",\" + dr + \" 0 0,1 \" + d.target.x + \",\" + d.target.y;\n  });\n    \n    textElements\n        .attr(\"x\", node => node.x)\n        .attr(\"y\", node => node.y)\n    \n    node\n        .attr(\"cx\", d => d.x)\n        .attr(\"cy\", d => d.y);\n  });\n\n  invalidation.then(() => simulation.stop());\n  \n  return svg.node();\n}\ndata_3 = FileAttachment(\"../../data/cleaned_data/bigrams_walk.json\").json()\n\ndrag_3 = simulation => {\n  \n  function dragstarted(d) {\n    if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n    d.fx = d.x;\n    d.fy = d.y;\n  }\n  \n  function dragged(d) {\n    d.fx = d3.event.x;\n    d.fy = d3.event.y;\n  }\n  \n  function dragended(d) {\n    if (!d3.event.active) simulation.alphaTarget(0);\n    d.fx = null;\n    d.fy = null;\n  }\n  \n  return d3.drag_3()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn conclusion, we can see that people’s attitudes toward different types of transportation in DC vary based on the insights obtained from sentiment analysis and visualizations. Although people tend to comment on bicycles more favorably than on walking or driving, all categories also draw criticism. The analysis of the pairs of words additionally sheds light on how different types of transportation relate to multiple parts of the city. For instance, while bigrams related to cars refer to suburbs like Maryland and Virginia, bigrams related to bikes concentrate on specific streets and blocks. While biking and walking are associated with more popular destinations like parks, museums, and monuments. Urban planners and policymakers may find this information helpful in understanding how various modes of transportation are used and in making decisions about urban planning and transportation infrastructure. It’s interesting to note that the positive comments for the walk category are concentrated around a few popular neighborhoods and landmarks in Washington, DC, indicating that the perception of the city’s walkability may be influenced by the presence of popular destinations. Furthermore, the negative bigrams associated with automobiles, such as pedestrian fatalities and traffic safety, indicate that there are significant issues that require attention in order to increase safety and accessibility. To conclude this section, we wanted to highlight a particularly eloquent Reddit comment on the walkability gap in Washington, D.C.:\n“I often times see”making DC a better place to live”, but the question I ask often is “for who?”. For those making enough to live in the inner-most part of the city? How do lower/working class individuals work, live, and enjoy this same city when the commute to do so.. is becoming unmanageable?“"
  },
  {
    "objectID": "index.html#conclusion",
    "href": "index.html#conclusion",
    "title": "Walkability in D.C.",
    "section": "Conclusion",
    "text": "Conclusion\nOverall, we explored the ease of access in various neighborhoods by foot and by bike, the correlation of walkability to socioeconomic and health outcomes, and sentiment around walkability in Washington, D.C. First, we see that walkability is associated with mixed socioeconomic outcomes, based on geographic area: while all outer parts of Washington, D.C. have low walkability, the top edges have higher car ownership and socioeconomic outcomes, whereas the low edges have low car ownership and poorer socioeconomic outcomes. Second, we see that low walkability is generally associated with poorer health outcomes, which makes sense because having decreased access to walking would limit mobility and health outcomes. After examining walkability and its assocation with various outcomes, we examined bikability and noticed that there are more neighborhood-downtown bike lanes and fewer neighborhood-neighborhood bike lanes. Given that housing and spending are generally higher in downtown areas, this trend makes it more expensive and unsafe to travel between lower-income areas. Finally, we investigated public sentiment on walking, biking, and cars in Washington, D.C. and discovered that people tend to comment on bicycles more favorably than on walking or driving, all categories also draw criticism.\nIt is important to note that various socioeconomic and health outcomes as well as walkability are interconnected and contribute to a complex web of influences on each other. Overall, our findings show that higher walkability in neighborhoods can promote physical activity, access to healthy food, and overall environmental and socioeconomic well-being, which in turn can positively impact various health metrics. If we had more time to conduct this study, we would love to explore the interactions between socioeconomic and health metrics to help us contextualize the relationship between walkability and such outcomes, so to have a better understanding of the causal and correlational relationships between these factors. For our text data, we would also further contextualize the sentiment analysis and differentiate between sentences like “I hate that walkability in Washington, D.C. is bad” and “I hate walking in Washington, D.C.” to obtain more accurate findings.\nAs Washington, D.C. is among the most walkable cities in the US, we hope that this study can increase awareness of the importance of walkability and even inspire future initiatives in improving walkability in Washington, D.C. and other cities too. Having an equitable access to amenities like grocery stores and community health centers is vital to positive outcomes, and we hope that this study might inspire you to find ways to learn more about and promote walkability in where you live."
  },
  {
    "objectID": "index.html#works-cited",
    "href": "index.html#works-cited",
    "title": "Walkability in D.C.",
    "section": "Works Cited",
    "text": "Works Cited"
  },
  {
    "objectID": "data_collection.html#data-collection",
    "href": "data_collection.html#data-collection",
    "title": "Collection",
    "section": "Data collection",
    "text": "Data collection\nDatasets and how did we gather them\n\nByclicles\nWalkability\nHealth\nSentiment\nIncome\n\nAPI, websites (include links), problems with the data Cras viverra, magna nec mattis mollis, purus ex malesuada lectus, id posuere felis elit ac lacus. Morbi scelerisque molestie libero, eget consequat metus vehicula a. In hac habitasse platea dictumst. Sed pretium feugiat nisl vitae sodales. Maecenas aliquam porttitor vestibulum. Praesent fringilla lectus tempus porta tincidunt. Ut velit arcu, pellentesque id interdum at, mollis eu dui. Sed sollicitudin elit velit, nec eleifend nisl dictum at.\nAliquam eu iaculis tellus, a lacinia lacus. Donec at placerat orci, suscipit maximus neque. Vivamus aliquet accumsan ultricies. Vivamus turpis mi, hendrerit nec massa vitae, ultricies laoreet ipsum. Cras et libero sem. Etiam at lectus ut lacus iaculis pretium. Phasellus cursus, justo in imperdiet commodo, justo odio commodo urna, in scelerisque diam dolor ac mauris. Fusce sapien tortor, dictum vitae nisi quis, rutrum faucibus est. Integer maximus eleifend efficitur. Nullam ut risus ac neque vehicula gravida et pulvinar orci. Curabitur nec hendrerit quam.\nFusce ac eleifend est, et scelerisque mauris. Aliquam dignissim sem id libero mattis varius. Integer tempus semper lacus eget eleifend. Aenean iaculis, dui in commodo pharetra, justo nisl porttitor ex, a posuere nisi erat sit amet enim. Nulla mattis nec dui ac convallis. Quisque gravida mauris sed posuere dignissim. Nam placerat nunc mattis ultrices scelerisque. Etiam lectus odio, cursus a neque a, consectetur dictum urna."
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Methods",
    "section": "",
    "text": "In order to investigate whether walkability has an impact on other aspects of peoples’ lives, we wanted to compare different socioeconomic outcomes of different neighborhoods depending on each one’s walkability. In order to accomplish this, we looked for walkability data, and socioeconomic outcomes that had granularity on the neighborhood level. We were able to accomplish this analysis with the following datasets:\n\nEPA Walkability Index: This dataset compiles different features about a specific census tract1, and computes a walkability score for each census tract. Certain D.C. neighborhoods are comprised of several census tracts, depending on the population density of that neighborhood.2\nU.S. Census Bureau Community Resilience Estimates: This dataset compiles different socioeconomic factors about each census block. The ones we chose to analyze were percentage of the households that fall under the poverty threshold, high school completion rates, income inequality, and vehicle ownership.\nU.S. Census Tract D.C. GeoJSON: This file is the GeoJSON map file created by the U.S. Census Bureau for Washington, D.C.. It includes a geographical information regarding the location of each neighborhood in Washington, D.C.\n\n1 A census tract is a geographic region defined for the purpose of taking a census. There are 179 census tracts in Washington, D.C. 2 Census tracts generally have a population size between 1,200 and 8,000 people, with an optimum size of 4,000 people. A census tract usually covers a contiguous area; however, the spatial size of census tracts varies widely depending on the density of settlement.\n\n\n\nIn order to create a clean dataset in the format we wanted, we created a script that subsetted the raw data for D.C. in each data source and only include the columns of interest. We then joined the files by using the Census Block ID column. Most of the columns were percentages, but some of them - like the walkabilty column - were in a score that was comprised of a different range of numbers. In order to ensure that the visualizations would enable easy comparison between each of the factors, each of the outcomes columns was rescaled to have a 0-100 range. Then, we conducted some basic data, including converting missing or negative values to NaN values, renaming columns, and melting data. The JSON data with the geographic boundaries for each DC census tract did not require any cleaning.\n\n\nCode\nfrom IPython.display import display, HTML\nimport altair as alt\nimport pandas as pd\nimport geopandas as gpd\nfrom pathlib import Path\nimport requests\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\"\"\"\nIMPORT DATA\n\"\"\"\n\n# define data directory\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nwrite_data_dir = data_dir/\"cleaned_data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\n\n# import data\nwalkability = pd.read_csv(data_dir/\"joined_depression_cre_walkability.csv\")\nwalkability.loc[:, 'geoid_tract_20'] = walkability.geoid_tract_20.astype(str)\nnation = pd.read_csv(data_dir/\"cleaned_data\"/\"nation-joined_depression_cre_walkability.csv\")\n\n# # Ingest GEOJSON file of census tracts in DC and grab json\n# req_dc = requests.get('https://raw.githubusercontent.com/arcee123/GIS_GEOJSON_CENSUS_TRACTS/master/11.geojson')\n# json_dc = req_dc.json()\n\n# # create geopandas dataframe and add in the walkability / outcomes data\n# geo_df = gpd.GeoDataFrame.from_features((json_dc))\n# merged_df = geo_df.merge(walkability,\n#                          how = 'left',\n#                          left_on = 'GEOID',\n#                          right_on='geoid_tract_20')\nmerged_df = walkability.copy(deep=True)\n\n\n\"\"\"\nNORMALIZE SCORES ACROSS ALL METRICS\n\"\"\"\n\n# convert the walkability score into a scale from 0 to 100 to make it more easier to interpret\n# original range 1-20\n# new desired range: 0-100\noriginal_range_min = 1\noriginal_range_max = 20\nnew_range_max = 100\nnew_range_min = 0 \n\nmerged_df.loc[:, 'walkability_score_scaled'] = merged_df.loc[:, 'walkability_score'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\nnation.loc[:, 'walkability_score_scaled'] = nation.loc[:, 'walkability_score'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\n\n# convert the income inequality index score into a scale from 0 to 100 to make it easier to interpret\n# original range 0-1\n# new desired range: 0-100\noriginal_range_min = 0\noriginal_range_max = 1\nnew_range_max = 100\nnew_range_min = 0 \n\nmerged_df.loc[:, 'income_inequality_gini_index'] = merged_df.loc[:, 'income_inequality_gini_index'].apply(lambda x: x if x >= 0 else np.nan)\nmerged_df.loc[:, 'income_inequality_gini_index_scaled'] = merged_df.loc[:, 'income_inequality_gini_index'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\nnation.loc[:, 'income_inequality_gini_index'] = nation.loc[:, 'income_inequality_gini_index'].apply(lambda x: x if x >= 0 else np.nan)\nnation.loc[:, 'income_inequality_gini_index_scaled'] = nation.loc[:, 'income_inequality_gini_index'].apply(lambda x: ((x - original_range_min) / (original_range_max - original_range_min)) * (new_range_max - new_range_min) + new_range_min)\n\n\n# define columns to report\noutcomes_cols = ['walkability_score_scaled',\n                 'below_poverty_level_perc',\n                 'income_inequality_gini_index_scaled',\n                 'hs_grad_perc',\n                 'households_no_vehicle_perc']\n\nfor i in outcomes_cols:\n    merged_df[i] = merged_df[i].apply(lambda x: x if x >= 0 else np.nan)\n    nation[i] = nation[i].apply(lambda x: x if x >= 0 else np.nan)\n    \n# flip metric to be percent of households with a car\nmerged_df.loc[:, 'households_w_vehicle'] = 100 - merged_df['households_no_vehicle_perc']\nnation.loc[:, 'households_w_vehicle'] = 100 - nation['households_no_vehicle_perc']\n\n\n\n\"\"\"\nCLEAN COLUMN NAMES\n\"\"\"\ncol_mapping = {'below_poverty_level_perc': '% Below Poverty Level',\n               'income_inequality_gini_index_scaled': 'Income Inequality Gini Score',\n               'hs_grad_perc': '% HS or Higher Degree',\n               'households_w_vehicle': '% with a Vehicle',\n               'walkability_score_scaled': 'Walkability Score',\n               'neighborhood_name': 'Neighborhood Name'}\n\nmerged_df = merged_df.rename(col_mapping, axis='columns')\n\n\n\"\"\"\nRE-FORMAT DATA\n\"\"\"\n# turn the dataframe into long data so that the bar chart can be created with each outcome as a bar\nneighborhood_df = pd.melt(merged_df,\n                          id_vars = 'Neighborhood Name',\n                          value_vars = col_mapping.values())\n\nneighborhood_df = neighborhood_df.groupby(['Neighborhood Name', 'variable'])['value'].mean().reset_index()\nwalk_scores = dict(zip(list(neighborhood_df[neighborhood_df.variable=='Walkability Score']['Neighborhood Name']),\n                       list(neighborhood_df[neighborhood_df.variable=='Walkability Score']['value'])\n                      ))\nneighborhood_df.loc[:, 'Walkability Score'] = neighborhood_df['Neighborhood Name'].map(walk_scores)\n\n# reformat to get the averages\nnation = nation[outcomes_cols+['households_w_vehicle']]\nnation.drop('households_no_vehicle_perc', axis='columns', inplace=True)\nnation_avg = pd.melt(nation,\n                     value_vars = [i for i in col_mapping.keys() if 'neighborhood_name' not in i])\nnation_avg = nation_avg.groupby('variable')['value'].mean().reset_index()\n\n# create cleaned column for plotting the national averages\nnation_avg['National Average'] = nation_avg['variable'].map(col_mapping)\n\n# create DC average walkability score\nneighborhood_df['dc_avg_walk'] = merged_df['Walkability Score'].mean()\n\n# add URL to the american flag icon\nnation_avg['flag_url'] = 'https://upload.wikimedia.org/wikipedia/commons/d/de/Flag_of_the_United_States.png'\n\n# write data to CSV\nneighborhood_df.to_csv(write_data_dir/\"neighborhood_walkability.csv\", index = False)\nnation_avg.to_csv(write_data_dir/\"national_walkability.csv\", index = False)\nmerged_df.to_csv(write_data_dir/\"cleaned_walkability.csv\", index = False)\n\n\n\n\n\nUsing the Pandas, Geopandas, and Altair libraries, we generated an interactive visualization of walkability and socio-economic outcomes in Washington, D.C. To generate the interactive visualization, we used the Altair library to create a bar chart with tract or neighborhood names on the x-axis, variable names on the y-axis, and variable values as the bar heights. We further aggregate the data at the national level by calculating the average of the variable values for all neighborhoods, and store the aggregated data in a separate dataframe.\n\n\nCode\nimport matplotlib as mpl\n\n# define data directories\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nwrite_data_dir = data_dir/\"cleaned_data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\n\n# read in cleaned data\nneighborhood_df = pd.read_csv(write_data_dir/\"neighborhood_walkability.csv\")\nnation_avg = pd.read_csv(write_data_dir/\"national_walkability.csv\")\nmerged_df = pd.read_csv(write_data_dir/\"cleaned_walkability.csv\")\n\n# Ingest GEOJSON file of census tracts in DC and grab json\nreq_dc = requests.get('https://raw.githubusercontent.com/arcee123/GIS_GEOJSON_CENSUS_TRACTS/master/11.geojson')\njson_dc = req_dc.json()\n\n# create geopandas dataframe and add in the walkability / outcomes data\ngeo_df = gpd.GeoDataFrame.from_features((json_dc))\nmerged_df.loc[:, 'geoid_tract_20'] = merged_df.geoid_tract_20.astype(str)\nmerged_df = geo_df.merge(merged_df,\n                         how = 'left',\n                         left_on = 'GEOID',\n                         right_on='geoid_tract_20')\n\n\n\"\"\"\nCREATE VISUALIZATION\n\"\"\"\n\n# open custom matplotlib sheet\nmpl.rc_params_from_file('style_sheet.mplstyle')  # load custom style sheet\n\n# define a click on the chloropleth map so that it can filter the bar chart\nclick = alt.selection_multi(fields=['Neighborhood Name'])\n\n# create the chloropleth map\nchoropleth = (alt.Chart(merged_df,\n                        title = \"Walkability of DC Census Tracts\"\n                       )\n              .mark_geoshape(stroke='white')\n              .transform_lookup(\n                                lookup='geoid_tract_20',\n                                from_=alt.LookupData(merged_df,\n                                                     'geoid_tract_20',\n                                                     ['Walkability Score', 'Neighborhood Name'])\n              ).encode(\n                    alt.Color('Walkability Score:Q',\n                              scale=alt.Scale(scheme='redyellowblue',\n                                              reverse=True\n                                             ),\n                              title = \"DC Walkability\"\n                             ),\n                    opacity=alt.condition(click,\n                                          alt.value(1),\n                                          alt.value(0.2)),\n                    tooltip=['Neighborhood Name:N', 'Walkability Score:Q'])\n              .add_selection(click)\n             )\n\nbars = (\n    alt.Chart(neighborhood_df,\n              title='Outcomes of DC Neighborhoods')\n    .mark_bar()\n    .encode(\n        x = alt.X('variable:N',\n                  axis=alt.Axis(labelAngle=-45)),\n        color = 'mean(Walkability Score):Q',\n        y = alt.Y('mean(value):Q',\n                  sort='x',\n                  scale = alt.Scale(domain = [0, 100])\n                 ),\n        tooltip = [\n                 'variable:N',\n                 'mean(value):Q'\n                ]\n    ).properties(\n        width = 200,\n        height = 300\n    ).transform_filter(click))\n\n# modify the axes and title labels\nbars.encoding.y.title = 'Avg. Value Across All Census Tracts'\nbars.encoding.x.title = 'Outcome'\n\nnation_avg_lines = (alt.Chart(nation_avg)\n                    .mark_tick(\n                        color=\"black\",\n                        thickness=3,\n                        size=39,  # controls width of tick\n                        strokeDash=[1,2]\n                    )\n                    .encode(\n                        x = 'National Average:N',\n                        y='value:Q'\n                    ))\n\nnation_avg_img = (alt.Chart(nation_avg)\n                    .mark_image(\n                        width=15,\n                        height=15)\n                    .encode(\n                        x='National Average:N',\n                        y='value:Q',\n                        url='flag_url',\n                        tooltip = ['National Average', 'value:Q']\n                    ))\n                    \nalt.themes.enable('vox')  # add theme\n# plot the two graphs together\nalt.hconcat(choropleth, (bars+nation_avg_lines+nation_avg_img))\n\n\n\n\n\n\n\n\nWe obtained PLACES Census Health Data Estimation data. This dataset contains model-based census tract level estimates for PLACES 2022 release. PLACES covers the entire United States at county, place, census tract, and ZIP Code Tabulation Area levels. The estimates, on the other hand, are provided by CDC’s Division of Population Health, Epidemiology and Surveillance Branch. The data sources used are Behavioral Risk Factor Surveillance System (BRFSS) 2020/2019, Census Bureau 2010 population estimates, and American Community Survey (ACS) 2015-2019 estimates. 29 of these measures were mapped at the census tract level using GIS systems.\n\n\n\nWe first read in the PLACES Census Tract Data and conduct some basic cleaning, such as selecting only data related to Washington, D.C. and renaming columns. Then, to do some basic data exploration, we created an exploratory scatter plot using Plotly, where we can examine the relationship between pairs of user-selected health outcomes in D.C. on the x-axis and y-axis. We used a callback function, update_visibility, to update the visibility of the scatter plot traces based on the selected values from the drop-down menus.\n\n\nCode\n# import the csv\ndc_health_df = pd.read_csv('./PLACES__Census_Tract_Data__GIS_Friendly_Format___2022_release (1).csv')\n\n# filter for where StateAbbr = DC\ndc_health_df = dc_health_df[dc_health_df['StateAbbr'] == 'DC']\n\n# Resetting defaults and import plotly libraries\nimport plotly.io as pio\npio.renderers.default = \"browser\"\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport statsmodels.api as sm\nimport numpy as np\nfrom sklearn.metrics import r2_score\n\n\n# isolate only columns with CrudePrev in the name\ndc_health_df_prev = dc_health_df.filter(regex='CrudePrev')\ndf = dc_health_df_prev\n\n# Rename columns\ndf = df.rename(columns={'ACCESS2_CrudePrev': '% of Adults without Health Insurance', \n                        'ARTHRITIS_CrudePrev': '% of Adults with Arthritis', \n                        'BINGE_CrudePrev': '% of Adults who Binge Drink',\n                        'BPHIGH_CrudePrev': '% of Adults with High Blood Pressure',\n                        'BPMED_CrudePrev': '% of Adults with High Blood Pressure who take Blood Pressure Medication',\n                        'CANCER_CrudePrev': '% of Adults who were Diagnosed with Cancer',\n                        'CASTHMA_CrudePrev': '% of Adults who were Diagnosed with Asthma',\n                        'CERVICAL_CrudePrev': '% of Women who had a Pap Smear in the Past 3 Years',\n                        'CHD_CrudePrev': '% of Adults who were Diagnosed with Coronary Heart Disease',\n                        'CHECKUP_CrudePrev': '% of Adults who had a Routine Checkup in the Past Year',\n                        'CHOLSCREEN_CrudePrev': '% of Adults who had Cholesterol Checked in the Past 5 Years',\n                        'COLON_SCREEN_CrudePrev': '% of Adults who had a Colonoscopy or similar test in the Past 10 Years',\n                        'COPD_CrudePrev': '% of Adults who were Diagnosed with COPD (Chronic Obstructive Pulmonary Disease)',\n                        'COREM_CrudePrev': '% Prevalence of Older Adult Men aged >=65 years who are up to date on preventative health',\n                        'COREW_CrudePrev': '% Prevalence of Older Adult Women aged >=65 years who are up to date on preventative health',\n                        'CSMOKING_CrudePrev': '% of Adults who Currently Smoke',\n                        'DENTAL_CrudePrev': '% of Adults who had a Dental Visit in the Past Year',\n                        'DEPRESSION_CrudePrev': '% of Adults who were Diagnosed with Depression',\n                        'DIABETES_CrudePrev': '% of Adults who were Diagnosed with Diabetes',\n                        'GHLTH_CrudePrev': '% of Adults who reported their Health as not Good',\n                        'HIGHCHOL_CrudePrev': '% of Adults who were Diagnosed with High Cholesterol',\n                        'KIDNEY_CrudePrev': '% of Adults who were Diagnosed with Kidney Disease',\n                        'LPA_CrudePrev': '% of Adults who are Physically Inactive', \n                        'MAMMOUSE_CrudePrev': '% Women aged 50-74 years who had a Mammogram in the Past 2 Years',\n                        'MHLTH_CrudePrev': '% of Adults who reported their Mental Health as not Good',\n                        'OBESITY_CrudePrev': '% of Adults who were Obese',\n                        'PHLTH_CrudePrev': '% of Adults who reported their Physical Health as not Good',\n                        'SLEEP_CrudePrev': '% of Adults who reported their Sleep as not Good',\n                        'STROKE_CrudePrev': '% of Adults who were Diagnosed with Stroke',\n                        'TEETHLOST_CrudePrev': '% of Adults who have lost all of their Natural Teeth'})\n\n# list of health metrics for drop down menu\ncolumn_names = df.columns\n\n# Creating the initial scatter plot\nfig = go.Figure(go.Scatter(x=df[column_names[0]], y=df[column_names[1]], mode='markers'))\n\n# Label axes\nfig.update_xaxes(title_text='X Axis')\nfig.update_yaxes(title_text='Y Axis')\n\n# Setting the range for x and y axes\nfig.update_xaxes(range=[0, 100])\nfig.update_yaxes(range=[0, 100])\n\nfor col in column_names:\n    for col2 in column_names:\n        x = df[col]\n        y = df[col2]\n        fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name=col + ' vs ' + col2, showlegend=False, visible=False))\n\n\n# Update the visibility of the traces\n        \n\ndef update_visibility(selected_col, selected_col2):\n    for i, trace in enumerate(fig.data):\n        if trace.name == selected_col + ' vs ' + selected_col2:\n            trace.visible = True\n        elif trace.name == selected_col + ' vs ' + selected_col2 + ' Best Fit':\n            trace.visible = True\n        else:\n            trace.visible = False\n\n# Create the drop-down menus for x (col) and y (col2) axes of the scatter plot\ncol_dropdown = [{'label': col, 'value': col} for col in column_names]\ncol2_dropdown = [{'label': col2, 'value': col2} for col2 in column_names]\n\n# #Define the dropdown menu for x-axis\nbutton_layer_1_height = 1.08\nx_axis_dropdown = go.layout.Updatemenu(\n    buttons=list([dict(args=[{'x': [df[col]]}, update_visibility(col, col2)], label=col, method='update') for col in column_names]),\n    direction=\"down\",\n    pad={\"r\": 10, \"t\": 10},\n    showactive=True,\n    x=0.06,\n    xanchor=\"left\",\n    y=button_layer_1_height + 0.05,\n    yanchor=\"top\"\n)\n\n\n# Define the dropdown menu for y-axis\ny_axis_dropdown = go.layout.Updatemenu(\n    buttons=list([dict(args=[{'y': [df[col2]]}, update_visibility(col, col2)], label=col2, method='update') for col2 in column_names]),\n    direction=\"down\",\n    pad={\"r\": 10, \"t\": 10},\n    showactive=True,\n    x=0.06,\n    xanchor=\"left\",\n    y=button_layer_1_height,\n    yanchor=\"top\"\n)\n\n\n\n\n# Update the layout to include the dropdown menus\nfig.update_layout(\n    updatemenus=[x_axis_dropdown, y_axis_dropdown]\n)\n\n# Label axes\nfig.update_xaxes(title_text='X Axis')\nfig.update_yaxes(title_text='Y Axis')\n\n# Setting the range for x and y axes\nfig.update_xaxes(range=[0, 100])\nfig.update_yaxes(range=[0, 100])\n\n# Update plot sizing\nfig.update_layout(\n    width=900,\n    height=900,\n    autosize=False,\n    #margin=dict(t=100, b=0, l=0, r=0),\n)\n\n# add annotations\nfig.update_layout(\n    annotations=[\n        dict(\n            text=\"X Axis:\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height + 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        ),\n        dict(\n            text=\"Y Axis:\",\n            x=0,\n            xref=\"paper\",\n            y=button_layer_1_height - 0.025,\n            yref=\"paper\",\n            align=\"left\",\n            showarrow=False\n        )\n    ]\n)\n\n\n# Change background color to grey\nfig.update_layout(\n    plot_bgcolor='rgb(230, 230, 230)'\n)\n\n# Change scatter point color to red\nfig.update_traces(\n    marker=dict(color='red')\n)\n\n# Change font to Calibri\nfig.update_layout(\n    font=dict(family='Proxima Nova')\n)\n\n\n# Display the scatter plot with dropdown menus\nfig.show()\n\n\n\n\n\nBased on this we created a second graph where we explore the relationship between walkability and health outcomes. We created two drop-down menus using Plotly’s dcc.Dropdown. The selected values from the drop-down menus are passed to the update_visibility function, which then updates the scatter plot based on the selected health metrics. We then displayed the final plot using Plotly’s dcc.Graph.\n\n\n\n\n\n\nBike lanes and the Capital Bikeshare program are two major initiatives for improving quality of life and transportation access in D.C. by the D.C. Department of Transportation. Since these two initiatives go hand in hand, we decided to analyze them together in a single visualization. For this analysis we collected the following datasets:\n\nCapital Bikeshare Trip Data for March 2023: This dataset compiles all of the Capital Bikeshare trips completed by riders in the Washington D.C. metro area. It contains information such as start_at: starting bike dock, ended_at: ending bike dock, start_station_name: street name information for starting dock station, end_station_name: street name information for end dock station. It also includes the latitude and longitude information for the start and end locations of the rider’s trip.\nU.S. Census Tract D.C. GeoJSON: This file is the GeoJSON map file created by the U.S. Census Bureau for Washington, D.C.. It includes a geographical information regarding the location of each neighborhood in Washington, D.C.\nOpen Data DC Bike Lane GeoJSON: This GeoJSON file provided by the D.C. Government provides geographical information regarding the various bike lanes located throughout the city.\n\n\n\n\nSince the goal of this visualization was the show both the bike lane and bikeshare data on a single map, we cleaned the datasets to put them in the proper format. In the Capital Bikeshare dataset, each trip’s latitude and longitude was recorded from the point where the bike was activated at the dock. This meant that even though various rides started at the same bike dock, there were small variations in the recorded latitudes and longitudes. Thereforem, the latitude and longitude values were standardized for each bike station. Additionally, the bikeshare dataset contained data for the entire Washington D.C. metro area and since we focused our analysis to D.C. only, stations outside of the D.C. boundary were removed. Finally, any rows with incomplete trip values were removed.\nThe GeoJSON files did not undergo any processing and therefore were used as-is.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nimport plotly.graph_objects as go\nfrom vega_datasets import data\nimport requests\nimport json\nimport warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\n# Read in data\n\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nimg_dir = Path().absolute().parent.absolute().parent/\"data\"/\"img\"\n\nbikeshare_df = pd.read_csv(data_dir/\"202303-capitalbikeshare-tripdata.csv\")\n\n# Convert dates into datetime format\nbikeshare_df['started_at'] = pd.to_datetime(bikeshare_df['started_at'])\nbikeshare_df['ended_at'] = pd.to_datetime(bikeshare_df['ended_at'])\n\n# Drop rides with NaN values\nbikeshare_df.dropna(subset=['start_station_name'], inplace = True)\nbikeshare_df.dropna(subset=['end_station_name'], inplace = True)\n\n# Standardize longitude and latitude using start station\nbikeshare_df['start_lng'] = bikeshare_df['start_lng'].groupby(bikeshare_df['start_station_id']).transform('max')\nbikeshare_df['start_lat'] = bikeshare_df['start_lat'].groupby(bikeshare_df['start_station_id']).transform('max')\n\n# Create dataframe for joining\ntmp = bikeshare_df[['start_station_id', 'start_lng','start_lat']]\ntmp.drop_duplicates(inplace = True)\n\n# Merge using the common station id value\nbikeshare_df = bikeshare_df.merge(tmp, left_on = 'end_station_id', right_on = 'start_station_id')\n\n# Drop repeated columns and rename them\nbikeshare_df.drop(columns = ['end_lat', 'end_lng', 'start_station_id_y'], inplace = True)\nbikeshare_df.rename(columns = {'start_lat_x': 'start_lat', 'start_lng_x': 'start_lng', 'start_lat_y': 'end_lat', 'start_lng_y':'end_lng', 'start_station_id_x': 'start_station_id'}, inplace = True)\nbikeshare_df.to_csv(Path().absolute().parent.absolute().parent/\"data/cleaned_data/bikeshare_cleaned.csv\", index = False)\n\n\n\n\n\nIn the Altair plot, we combined March 2023 Capital Bikeshare Data with D.C. geographical data to create a layered visual. The geographical layout is a map of D.C. with each neighborhood outlined by white. Each point represents a Capital Bikeshare Station with the size representing the amount of trips starting from that station in the month of March. The yellow lines represent the bike lanes created by the D.C. government on public streets. When the user hovers over any station, the visual will show black network lines (or edges) that connect that station (“start” station) to other stations (“end” stations), representing where people have traveled to with the Capital Bikeshare bikes. We also included tooltips that display the station information and appear when a user hovers over a station.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nimport plotly.graph_objects as go\nfrom vega_datasets import data\nimport requests\nimport json\nimport warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nbikeshare_df = pd.read_csv(Path().absolute().parent.absolute().parent/\"data/cleaned_data/bikeshare_cleaned.csv\")\n# Create list of bikeshare stations outside of DC\nnondc_stations = [\n    32256,32251,32237,32241,32210,32225,32259,32223,32209,32240,32239,32245,32220,32214,32219,\n    32224,32217,32213,32239,32246,32247,32250,32248,32246,32228,32215,32238,32252,32249,32260,\n    32234,32231,32235,32255,32200,32208,32201,32211,32227,32207,32229,32221,32206,32233,32205,\n    32204,32205,32203,32206,32222,32230,32232,32600,32602,32603,32608,32605,32604,32607,32609,\n    31948,31904,32606,32601,31921,31905,31902,31901,31976,31036,31977,31900,31920,31049,31037,\n    31926,31919,31035,31973,31069,31023,31022,31021,31019,31020,31094,31092,31079,31030,31029,\n    31080,31093,31014,31062,31077,31073,31024,31040,31028,31017,31924,31027,31947,31066,31075,\n    31949,31053,31971,31067,31058,31923,31063,31068,31951,31945,31095,31006,31005,31091,31004,\n    31936,31071,31090,31950,31064,31935,31011,31012,31009,31944,31052,31010,31959,31916,31088,\n    31960,31956,31910,31083,31915,31087,31085,31913,31915,31970,31969,31906,31098,31048,31081,\n    31084,31082,31974,31930,31932,31953,31942,31967,32406,32423,32415,32407,32405,32401,32400,\n    32405,32404,32413,32418,32410,32403,32408,32421,32402,32417,32422,32420,32414,32412,32416,\n    32059,32061,32026,32011,32049,32082,32058,32025,32001,32058,32082,32024,32043,32036,32012,\n    32034,32035,32050,32056,32426,32425,32424,32426,32085,32094,32089,32093,32091,32090,32087,\n    32088,32086,32092,32022,32066,32064,32062,32065,32073,32063,32084,32054,32051,32040,32046,\n    32029,32055,32002,32021,32003,32048,32013,32000,32008,32028,32027,32053,32039,32057,32078,\n    32075,32077,32076,32079,32080,32074,32081,32032,32047,32044,32017,32007,32009,32023,32033,\n    32016,32004,32005,32072,32041,32052,32071,32038,32037,32045,32067,32069,32068,32018,32253,\n    32236,32243,32258,32216,32212,32218,32019,32411,31929,31914,31907,31903,31958,31933,31041,\n    31042,31968,31044,31045,31955,31046,31047,31099,31043,31097,31931,31918,31086,31927,31966,\n    21943,31963,31952,31964,31962,31908,31072,31941,31961,31928,31054,31033,31059,31057,31061,\n    31056,31055,31909,31912,31065,31032,31074,31078,32419,31957,31954,31946,31972,31060,31938,\n    31013,31002,31007,31000,31003,31096,31070,31039,31034,31025,31038,31026,31050,31940,31089,\n    31031,31051,31937,31016,31018,31039,31015,31917,31076,31939,32409\n]\n\nalt.data_transformers.enable('default',max_rows=None)\n\n#### BACKGROUND FOR DC MAP \n\n# Define background of Washington D.C.\nresponse1 = requests.get('https://raw.githubusercontent.com/arcee123/GIS_GEOJSON_CENSUS_TRACTS/master/11.geojson')\n\nbackground = alt.Chart(alt.Data(values=response1.json()), title= \"Map of D.C. Bike Lanes, Capital Bikeshare Stations, & Routes in March 2023\").mark_geoshape(\n        fill=\"lightgray\",\n        stroke='white',\n        strokeWidth=1\n    ).encode(\n    ).properties(\n        width=600,\n        height=600\n    )\n\n#### BACKGROUND FOR DC BIKE LANE LOCATIONS \n\n# Open GeoJSON file for bicycle lanes\nwith open(data_dir/'Bicycle_Lanes.geojson') as f:\n    data = json.load(f)\n\n\n# Create background of D.C.\nbackground_lanes = alt.Chart(alt.Data(values=data)).mark_geoshape(\n        stroke='#d6a320',\n        strokeWidth=1\n        ).properties(\n        width=600,\n        height=600\n    )\n\n\n\n#### MOUSEOVER SELECTION\n\n# Create mouseover selection\nselect_station = alt.selection_single(\n    on=\"mouseover\", nearest=True, fields=[\"start_station_name\"], empty='none'\n)\n\n#### NETWORK CONNECTIONS FOR MAP \n\n# Filter non-DC stations\ntmp1 = bikeshare_df[~bikeshare_df['start_station_id'].isin(nondc_stations)]\ntmp1 = tmp1[~tmp1['end_station_id'].isin(nondc_stations)]\n\n# Keep only relevant columns and drop duplicates to have one row per route\ntmp1 = tmp1[['start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng']].drop_duplicates()\n\n# Define connections\nconnections = alt.Chart(tmp1).mark_rule(opacity=0.35).encode(\n    latitude=\"start_lat:Q\",\n    longitude=\"start_lng:Q\",\n    latitude2=\"end_lat:Q\",\n    longitude2=\"end_lng:Q\"\n).transform_filter(\n    select_station\n)\n\n#### POINTS FOR MAP \n\n# Filter non-DC stations\ntmp2 = bikeshare_df[~bikeshare_df['start_station_id'].isin(nondc_stations)]\ntmp2 = tmp2[~tmp2['end_station_id'].isin(nondc_stations)]\n\n# Create boolean columns for rideable type and membet type\ntmp2['classic_bike'] = np.where(tmp2['rideable_type'] == 'classic_bike', 1, 0)\ntmp2['electric_bike'] = np.where(tmp2['rideable_type'] == 'electric_bike', 1, 0)\ntmp2['docked_bike'] = np.where(tmp2['rideable_type'] == 'docked_bike', 1, 0)\n\n# Temporary dataframe showing unique station locations with ride count\ntmp2 = tmp2[['start_station_name','start_station_id', 'start_lng', 'start_lat', 'ride_id', 'classic_bike', 'electric_bike', 'docked_bike']].groupby(['start_station_name', 'start_station_id','start_lng', 'start_lat']).agg({'ride_id': 'count', 'classic_bike': 'sum', 'electric_bike':'sum', 'docked_bike':'sum'}).reset_index()\ntmp2.rename(columns= {'ride_id':'count_rides', 'classic_bike': 'count_classic', 'electric_bike': 'count_electric', 'docked_bike': 'count_dock'}, inplace = True)\ntmp2['color'] = 'Bike Station'\n\npoints = alt.Chart(tmp2).mark_circle().encode(\n    latitude=\"start_lat:Q\",\n    longitude=\"start_lng:Q\",\n    color = alt.Color('color:N', title = \"Legend\", scale = alt.Scale(domain=['Bike Station', 'Bike Lane'],range=['#962e2ec8', '#d6a320'])),\n    size=alt.Size(\"count_rides:Q\", scale=alt.Scale(range=[15, 250]), legend=None),\n    order=alt.Order(\"count_rides:Q\", sort=\"descending\"),\n    tooltip=[\n             alt.Tooltip('start_station_id:Q', title='\\U0001f4cd Start Station ID'),\n             alt.Tooltip('start_station_name:N', title='\\U0001f6e3 Start Station Name'),\n             alt.Tooltip('count_rides:Q', title='\\U0001f50d Ride Count'),\n             alt.Tooltip('count_classic:Q', title='\\U0001f6b4 Classic Bike Count'),\n             alt.Tooltip('count_electric:Q', title='\\U0001f6b5 Electric Bike Count'),\n             alt.Tooltip('count_dock:Q', title='\\U0001f6b2 Docked Bike Count')\n             ]\n).add_selection(\n    select_station\n)\n\nalt.themes.enable('vox')  # add theme\n# Show visualization\n(background + background_lanes + connections + points).configure_view(stroke=None)\n\n\n\n\n\n\n\n\nTo obtain information about metro ridership, we went to WMATA, which has its own ridership data portal. The data is collected from the Metrorail Ridership Year-over-Year Change dashboard here. Only data for March 2023 is available, so then we went to the download button in the bottom right corner of the platform to downoload this data. For more information about the data collection method, please reach out to “planning_ridership@wmata.com”.\n\n\n\nIn answering this question, we built an interactive timeseries plot of the Washington Metropolitan Area Transit Authority (WMATA) Metro entries by selected station and date in March 2023 using the Plotly library. Then, we cleaned the data by renaming the ‘Date_This_Year’ and ‘Entry_This_Year’ columns to ‘Date’ and ‘Entries’ respectively for clarity. We also pivoted the dataframe so that number of entries are shown by station in columns and date in rows. Then, we converted the index column, which contains the dates, to datetime format. We also organized the index from earliest to latest date. Finally, we selected the stations Anacostia, Stadium-Armory, Van Ness-UDC, Shaw-Howard Univ, Gallery Place, and Capitol South from the dataframe because the first three neighborhoods correspond to three of the least walkable neighborhoods in Washington, D.C. and the last three neighborhoods correspond to the most walkable neighborhoods. Otherwise, if we included all stations’ data, the plot would be too crowded and confusing. We saved the cleaned data to a csv file.\n\n\nCode\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nwrite_data_dir = data_dir/\"cleaned_data\"\n# Read in data\ndf = pd.read_csv(data_dir / 'wmata.csv', encoding='utf-16', delimiter=\"\\t\")\n# Remove columns Servicetype_This_Year(group), Holiday_Last_Year, Holiday_This_Year, Servicetype_This_Year, Time_Period, and Date_Last_Year\ndf = df.drop(['Day_of_Date_This_Year', 'Servicetype_This_Year_(group)', 'Holiday_Last_Year', 'Holiday_This_Year', 'Servicetype_This_Year', 'Time_Period', 'Date_Last_Year', 'Entries_Last_Year'], axis=1)\n# Rename columns \ndf = df.rename(columns={'Date_This_Year': 'Date'})\ndf = df.rename(columns={'Entries_This_Year': 'Entries'})\n# Pivot data\npivot_df = df.pivot_table(index='Date', columns='Station', values='Entries')\n# Convert index of pivot_df to datetime\npivot_df.index = pd.to_datetime(pivot_df.index)\n# Organize index of pivot_df from earliest to latest date\npivot_df = pivot_df.sort_index()\n# Select stations Anacostia, Stadium-Armory, Van Ness-UDC, Shaw-Howard Univ, Gallery Place, and Capitol South from pivot_df\nnew_df = pivot_df[['Anacostia', 'Stadium-Armory', 'Van Ness-UDC', 'Shaw-Howard U', 'Gallery Place', 'Capitol South']]\n# weekly rides per station\n# Save pivot_df and new_df to csv\npivot_df.to_csv(write_data_dir / 'wmata_cleaned.csv', index= False)\nnew_df.to_csv(write_data_dir / 'wmata_new_cleaned.csv', index= False)\ndf.to_csv(write_data_dir / 'wmata_long_cleaned.csv', index= False)\n\n\n\n\n\nUsing the cleaned data, we built an interactive time series plot using the plotly.graph_objects and plotly.subplots libraries. We read in the cleaned data (wmata_new_cleaned.csv) and created a list of all the unique station names in the dataset. We created a subplot with one trace per station and used a for loop to iterate through each unique station in the dataset, adding the corresponding trace to the subplot. Then, we created a dropdown menu to allow users to input a station from the list of stations available. Each station is represented in a button. When a user picks a station by selecting the corresponding button, the method updates the visibility of the trace to reflect the entries by day at the selected station. The layout of the plot is updated to include the dropdown menu and to set the title, axis labels, and fixed axis ranges. The fig.show() method to display the plot.\n\n\nCode\n# Build interactive timeseries plot using plotly\n# Import libraries\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib as mpl\nmpl.rc_params_from_file('style_sheet.mplstyle')  # load custom style sheet\n# List all stations\nstations = list(new_df.columns)\n# Create subplot with one trace per station\nfig = make_subplots(rows=1, cols=1)\nfor station in stations:\n    fig.add_trace(\n        go.Scatter(x=new_df.index, y=new_df[station], name=station),\n        row=1, col=1\n    )\n# Create dropdown menu to select station\nbuttons = []\nfor station in stations:\n    buttons.append(\n        dict(method='update', label=station, args=[{'visible': [station == s for s in stations]}])\n    )\ndropdown = dict(\n    active=0, buttons=buttons, direction='down', showactive=True, x=1.1, y=1.1\n)\n# Update layout\nfig.update_layout(\n    updatemenus=[dropdown], height=600, width=900,\n    title='WMATA Metro Entries by Selected Station and Date in March 2023', xaxis_title='Date', yaxis_title='Entries',\n    yaxis=dict(range=[0, 3000])\n)\n# Show plot\nfig.show()\n#### Table\n# Import pivot_df from the file\ndf = pd.read_csv(write_data_dir / 'wmata_long_cleaned.csv')\ndf.Date = pd.to_datetime(df.Date)\nweekly_df = df.groupby([pd.Grouper(key='Date', freq='W'), 'Station'])[\n    'Entries'].sum().reset_index()\n# sort so that the one with most ridership per week is on top\nweekly_df = weekly_df.sort_values(\n    by=['Date', 'Entries'], ascending=[True, False])\n# format the dates so they look cleaner in the table\nweekly_df.Date = weekly_df.Date.dt.strftime('%B %-d')\n# format number of rides\nweekly_df['Entries'] = weekly_df['Entries'].apply(\n    lambda x: \"{:,}\".format(int(x)))\nheaderColor = '#962E2E'  # red part of theme\nrowEvenColor = '#FDE6AB'  # ligher yellow part of theme\nrowEvenColor2 = 'lightgray'  # ligher yellow part of theme\nrowOddColor = 'white'\nnum_stations = weekly_df.Station.nunique()\nnum_days = weekly_df.Date.nunique()\ntable_fig = go.Figure(data=[go.Table(\n    header=dict(\n        values=['Start of Week', 'Metro Station',\n                'Num. of Riders over 7 Days'],\n        line_color='darkslategray',\n        fill_color=headerColor,\n        align=['center'],\n        font=dict(color='white', size=12)\n    ),\n    cells=dict(\n        values=[weekly_df.Date, weekly_df.Station, weekly_df.Entries],\n        line_color='darkslategray',\n        # 2-D list of colors for alternating rows\n        fill_color=[[rowOddColor, rowEvenColor]*(int(len(df)/2)+len(df) % 2)],\n        # fill_color = [([rowOddColor]*num_stations+[rowEvenColor]*num_stations)*(int(num_days/2)+ (num_days%2))],\n        # fill_color = [([rowOddColor,rowEvenColor]*(int(num_stations/2)+(num_stations%2))+[rowOddColor,rowEvenColor2]*(int(num_stations/2)+(num_stations%2)))*(int(len(df)/(num_stations*2)) + len(df)%(num_stations*2))],\n        align=['center'],\n        font=dict(color='darkslategray', size=11)\n    ))\n])\ntable_fig.update_layout(title_text='Weekly D.C. Metro Ridership')\ntable_fig.update_layout({'margin': {'t': 50\n                                    }})\ntable_fig.show()\n# table_fig = go.Figure(data=[go.Table(\n#     header=dict(values=list(df.columns),\n#                 fill_color=\"#962E2E\",\n#                 align='left'),\n#     cells=dict(values=[df.Date, df.Station, df.Entries],\n#                fill_color='#FDFDFD',\n#                align='left'))\n# ])\n# table_fig.show()\n\n\n\n\n\n\n\n\nTo collect the sentiment of the public regarding different transportation methods we used the Reddit API to scrap answers to posts using keywords such as “Walkability”, “Cars” and “Bicycles”. The API would collect the opinions from the thread URL we are scrapping and finally a dataframe was generated with the content of each post.\n\n\nCode\nimport praw\nimport pandas as pd\n\n# Creating connection to API \nreddit_read_only = praw.Reddit(client_id=\"\",\n                            client_secret=\"\",\n                            user_agent=\"Walkability_DC\")\n\nsubreddit = reddit_read_only.subreddit(\"redditdev\")\n\nprint(\"Name:\", subreddit.display_name)\nprint(\"Title:\", subreddit.title)\nprint(\"Description:\", subreddit.description)\n\n# Gather url of predefined topics\ntopics = {\"bikes\":[bikes_urls],\n          \"cars\":[cars_urls],\n          \"walk\":[walk_urls],\n        }\n\n# Scrapping data by url\nfor key in topics.keys():\n    comments = []\n    for url in topics[key][0]:\n        try:\n                submission = reddit_read_only.submission(url=url)\n        except:\n             print(\"incorrect url:\",url)\n             continue\n        submission.comments.replace_more(limit=0)\n        for comment in submission.comments.list():\n            comments.append(comment.body)\n    topics[key].append(comments)\n\n# Generation of dataframe with all threads per category\ndf_reddit = pd.DataFrame(data=[topics[\"bikes\"][1],topics[\"cars\"][1],topics[\"walk\"][1]]).T\ndf_reddit = df_reddit.rename(columns={0:\"bikes\", 1:\"cars\", 2:\"walk\"})\n\ndf_reddit.to_csv(\"../data/reddit.csv\",index=False)\n\n\n\n\n\nA Natural Language Analysis was performed to: remove non-letter characters\n\n\nCode\nimport pandas as pd\nimport re\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport tensorflow as tf\nimport pandas as pd\nimport random\nimport numpy as np\nimport torch as torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom pysentimiento import create_analyzer\nimport json\n\n#opening previously obtained data\ndf = pd.read_csv('../data/reddit.csv')\ndf = df.fillna(\"\")\ndf.head()\n\n# function to clean strings\ndef remove_nonletters(strings):\n    pattern = re.compile(r\"[^a-zA-Z\\s]|[\\n]+\")\n\n    cleaned_strings = [(pattern.sub(\"\", i)).lower() for i in strings]\n    return cleaned_strings\n\nfor col in df.columns:\n    col_clean = str(col)+\"_clean\"\n    df[col_clean] = remove_nonletters(df[col])\n\n\nAfter cleaning characters we tokenized the texts to generate wordclous per category.\n\n\nCode\n#Cleaning stopwords\n\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.probability import FreqDist\nfrom nltk.corpus import stopwords\nimport re\n\ns_words=list(stopwords.words('english'))\nextra_s_words = [\"the\",\"to\",\"a\",\"and\",\"of\",\"i\",\"is\",\"you\",\"it\",\"i\",\"is\",\"ive\",\"youve\",\"im\",\"dc\",\"youre\",\"dont\",\"would\",\"also\",\"might\"]\nfor i in extra_s_words:\n     s_words.append(i)\n\npattern = re.compile(r'\\s*\\b(' + '|'.join(s_words) + r')\\b\\s*', re.IGNORECASE)\n\nx = [\"bikes_clean\",\n     \"cars_clean\",\n     \"walk_clean\"]\n\nwords = {}\n\nfor col in x:\n    tokens = [word_tokenize(pattern.sub(' ', i)) for i in df[col]]\n    words[col] = \" \".join([word for sentence in tokens for word in sentence])\nwords\n\n# Obtaining the frequency of each word\nfdists= {}\n\nfor key in words.keys():\n    tokenized_words = nltk.tokenize.word_tokenize(words[key])\n    fdist = FreqDist(tokenized_words)\n    fdists[key] = fdist\nfdists\n\n#obtaining the top frequent values and generating string to be consumed by the script to generate the wordcloud vis \nwords_freq = []\nfor key_n in fdists.keys():\n    fdist = (dict(fdists[key_n].most_common(30)))\n    result =\"\"\n    total =  sum(fdist.values())\n    for key, value in fdist.items():\n        n = (value*100) // total\n        result+= (key+\" \")*n\n    words_freq.append(result)\nwords_freq\n\n\nFurthermore, to obtain the sentiment of each opinion we used a pre-trained BERT model to predict Negative, Neutral and Positive sentiment.\n\n\nCode\n#Calling a bert tranformer\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n\n#predicting sentiment using analyzer \n\nfor i in [\"walk\",\"bikes\",\"cars\"]:\n    file_name = \"../data/\"+i+\".txt\"\n    df = pd.read_csv(file_name)\n    df = df.dropna\n    col = i+\"_clean\"\n    sentiment = [analyzer.predict(i) for i in df[col]]\n    sent_label = [i.output for i in sentiment]\n    sent_prob = [i.probas for i in sentiment]\n\n    df_probs = pd.DataFrame(sent_prob)\n    df_probs[\"label\"] = sent_label\n    df_probs[\"walk\"] = df[\"walk_clean\"]\n    \n    file_name = \"../data/\"+i+\".csv\"\n    df_probs.to_csv(file_name)\n\n#opening previously modified sentiment analysis\nb_sent = pd.read_csv(\"../data/bikes_sent.csv\")\nc_sent = pd.read_csv(\"../data/cars_sent.csv\")\nw_sent = pd.read_csv(\"../data/walk_sent.csv\")\n\n# drop index\nb_sent = b_sent.drop(columns=['Unnamed: 0'])\nc_sent = c_sent.drop(columns=['Unnamed: 0'])\nw_sent = w_sent.drop(columns=['Unnamed: 0'])\n\n# add category\nb_sent[\"category\"] = \"bike\"\nc_sent[\"category\"] = \"car\"\nw_sent[\"category\"] = \"walk\"\n\nb_sent = b_sent.rename(columns={\"bikes\": \"text\"})\nc_sent = c_sent.rename(columns={\"cars\": \"text\"})\nw_sent = w_sent.rename(columns={\"walk\": \"text\"})\n\n#generate a single dataframe\ndf_sent = b_sent.append([c_sent,w_sent], ignore_index = True)\ndf_sent.shape\n\n\nFinally to have a better understanding of the sentiment we want to analyze the bigrams of words in each category to understand the words behind the opinions.\n\n\nCode\nimport nltk\nfrom functools import reduce\n# Obtaining bigrams and generating a dictionary with their frequency\n\nbigram_freqs = []\nj = 0\n\ncategories = [words[cat] for cat in words.keys()]\nflattened_text = \" \".join([text for text in [words['bikes_clean'],words['cars_clean'],words['walk_clean']]])\ncategories.append(flattened_text)\n\nfor cat in categories:\n    #obtaining bigrams per category\n    x = pattern.sub(' ',cat )\n    x = x.replace(\"  \",\" \").replace(\"  \",\" \")\n    tokens = nltk.word_tokenize(x)\n    bigrams = list(nltk.bigrams(tokens))\n\n    y = {i:0 for i in set(bigrams)}\n\n    for bigram in bigrams:\n        y[bigram] += 1\n    bigram_freqs.append(dict(y))\n\n\"\"\"\nTo observe the bigrams on a network diagram we want to store the values and their frequency on a json file with the next syntaxis:\ndata = {\"nodes\" : [{\"name\":\"A Chifolleau\",\"n\":1,\"grp\":1,\"id\":\"A Chifolleau\"}\n        \"links\" =[[{\"source\":\"A Besnard\",\"target\":\"M Ardisson\",\"value\":1},{\"source\":\"A Besnard\",\"target\":\"Y Holtz\",\"value\":1},\n\"\"\"\ndef transform_dict(input_dict):\n    unique_words = set()\n    for key in input_dict.keys():\n        unique_words.add(key[0])\n        unique_words.add(key[1])\n\n    word_to_id = {word: i+1 for i, word in enumerate(sorted(unique_words))}\n\n    #nodes = [{'name': word, 'value': word_to_id[word], 'colour': '#bde0f6'} for word in sorted(unique_words)]\n    nodes = [{'name': word, 'n': word_to_id[word], \"grp\":1, \"id\":word} for word in sorted(unique_words)]\n\n    links = []\n    for key, value in input_dict.items():\n        source = word_to_id[key[0]]\n        target = word_to_id[key[1]]\n        #links.append({'source': word, 'target': target, 'value': value})\n        links.append({'source': key[0], 'target': key[1], 'value': value})\n\n    return {'nodes': nodes, 'links': links}\n\n\n#Function to reduce the dictionary to contain values only with 3 connections or more\ndef filter_dict(d):\n    return {k: v for k, v in d.items() if v >= 3}\n\n\nfiltered_bigrams = [filter_dict(i) for i in bigram_freqs]\nnetworks =[transform_dict(i) for i in filtered_bigrams]\n\n#storing all dictionaries in json files\n\ncat = [\"bikes\", \"cars\", \"walk\", \"all\"]\nfor i in range(0,len(cat)):\n    filename = \"../data/bigrams_\"+cat[i]+\".json\"\n    with open(filename, 'w') as fp:\n        json.dump(networks[i],fp,indent=4)\n\n\n\n\n\nWe generated visualizations using Plotly library in Python to analyze sentiment polarity of comments related to different categories (bike, walk, and car). We first load and clean data from three different CSV files (b_sent.csv, c_sent.csv, and w_sent.csv) which contain sentiment analysis results for reddit comments related to bikes, cars, and walking, respectively. Next, we create three box plots using Plotly, one for each category of transport. We plotted the sentiment polarity values on the y-axis, and the categories on the x-axis. After the first graph, we create a 2D histogram contour plot and two more histograms. The contour plot (trace2) shows the density of sentiment polarity values for each category, with darker areas indicating higher density. The two histograms (trace3 and trace4) show the distribution of sentiment polarity values along the x-axis and categories along the y-axis separately. The final visualizations provide insights into the sentiment polarity of comments related to different categories, allowing for a comparison of sentiment distribution across categories.\n\n\nCode\ntrace0 = go.Box(\n    y=y0,\n    name = 'bike',\n    marker = dict(\n        color = 'rgba(148, 46, 46, 0.784)',\n    ),\n    notched=True\n)\ntrace1 = go.Box(\n    y=y1,\n    name = 'walk',\n    marker = dict(\n        color = 'rgb(153, 91, 40)',\n    ),\n    notched=True\n)\ntrace2 = go.Box(\n    y=y2,\n    name = 'car',\n    marker = dict(\n        color = 'rgb(214, 163, 32)',\n    ),\n    notched=True\n)\n\ndata = [trace0, trace1, trace2]\nlayout = go.Layout(\n    title = \"Sentiment polarity boxplot by category\"\n)\n\nfig = go.Figure(data=data,layout=layout)\niplot(fig, filename = \"Sentiment polarity boxplot by category\")\n\n\ntrace1 = go.Scatter(\n    x=df_sent['polarity'], y=df_sent['category'], mode='markers', name='points',\n    marker=dict(color='rgb(102,0,0)', size=2, opacity=0.4)\n)\ntrace2 = go.Histogram2dContour(\n    x=df_sent['polarity'], y=df_sent['category'], name='density', ncontours=30,\n    colorscale='Hot', reversescale=True, showscale=False,\n    hovertemplate='<br>Polarity: %{x}<br>Category: %{y}<br>Comments: %{z}'\n)\ntrace3 = go.Histogram(\n    x=df_sent['polarity'], name='Polarity',\n    marker=dict(color='rgb(214, 163, 32)'),\n    yaxis='y2',\n    hovertemplate='<br>%{x}<br>'\n)\ntrace4 = go.Histogram(\n    y=df_sent['category'], name='Category', marker=dict(color='rgba(148, 46, 46, 0.784)'),\n    xaxis='x2'\n)\ndata = [trace1, trace2, trace3, trace4]\n\nlayout = go.Layout(\n    showlegend=False,\n    autosize=False,\n    width=800,\n    height=750,\n    xaxis=dict(\n        domain=[0, 0.85],\n        showgrid=False,\n        zeroline=False\n    ),\n    yaxis=dict(\n        domain=[0, 0.85],\n        showgrid=False,\n        zeroline=False\n    ),\n    margin=dict(\n        t=50\n    ),\n    hovermode='closest',\n    bargap=0,\n    xaxis2=dict(\n        domain=[0.85, 1],\n        showgrid=False,\n        zeroline=False\n    ),\n    yaxis2=dict(\n        domain=[0.85, 1],\n        showgrid=False,\n        zeroline=False\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\nfig.update_layout(yaxis_title=\"Category\",xaxis_title=\"Polarity\", title=\"Sentiment polarity of posts by category\") \n\niplot(fig, filename='2dhistogram-2d-density-plot-subplots')\n\n\n\n\nCode\nchart = {\n  const links = data.links.map(d => Object.create(d));\n  const nodes = data.nodes.map(d => Object.create(d));\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", d3.forceLink(links).id(d => d.id).distance(40))\n      .force(\"charge\", d3.forceManyBody().strength(-40))\n      .force('collision', d3.forceCollide().radius(10))\n      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n\n  const svg = d3.select(DOM.svg(width, height));\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke-opacity\", 0.2)\n    .selectAll(\"path\")\n    .data(links)\n    .join(\"path\")\n      .attr(\"stroke-width\", 2)\n      .attr(\"stroke\", color)\n      .attr(\"fill\", \"transparent\");\n\n  const node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 0)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", 6)\n      .attr(\"fill\", \"#555\")\n      .call(drag(simulation))\n  \n  const textElements = svg.append('g')\n    .selectAll('text')\n    .data(nodes)\n    .enter().append('text')\n      .text(node => node.id)\n      .attr('font-size', 10)\n      .attr(\"font-family\", \"Helvetica\")\n      .attr(\"fill\", \"#555\")\n      .attr('dx', 10)\n      .attr('dy', 4)\n\n  simulation.on(\"tick\", () => {\n    link\n      .attr(\"d\", function(d) {\n      var dx = d.target.x - d.source.x,\n          dy = d.target.y - d.source.y,\n          dr = Math.sqrt(dx * dx + dy * dy);\n      return \"M\" + d.source.x + \",\" + d.source.y + \"A\" + dr + \",\" + dr + \" 0 0,1 \" + d.target.x + \",\" + d.target.y;\n  });\n    \n    textElements\n        .attr(\"x\", node => node.x)\n        .attr(\"y\", node => node.y)\n    \n    node\n        .attr(\"cx\", d => d.x)\n        .attr(\"cy\", d => d.y);\n  });\n\n  invalidation.then(() => simulation.stop());\n  \n  return svg.node();\n}\ndata = FileAttachment(\"../../data/cleaned_data/bigrams_bikes.json\").json()\n\nheight = 600\ncolor = {\n  const scale = d3.scaleOrdinal(d3.schemeSet1);\n  return d => scale(d.group);\n}\ndrag = simulation => {\n  \n  function dragstarted(d) {\n    if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n    d.fx = d.x;\n    d.fy = d.y;\n  }\n  \n  function dragged(d) {\n    d.fx = d3.event.x;\n    d.fy = d3.event.y;\n  }\n  \n  function dragended(d) {\n    if (!d3.event.active) simulation.alphaTarget(0);\n    d.fx = null;\n    d.fy = null;\n  }\n  \n  return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nd3 = require(\"d3@7\")\nd3Cloud = require(\"d3-cloud@1\")\nimport {howto} from \"@d3/example-components\"\n\nfunction WordCloud(title,text, {\n  size = group => group.length, // Given a grouping of words, returns the size factor for that word\n  word = d => d, // Given an item of the data array, returns the word\n  marginTop = 0, // top margin, in pixels\n  marginRight = 0, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 0, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  maxWords = 250, // maximum number of words to extract from the text\n  fontFamily = \"sans-serif\", // font family\n  fontScale = 30, // base font size\n  padding = 0, // amount of padding between the words (in pixels)\n  rotate = 0, // a constant or function to rotate the words\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  const words = typeof text === \"string\" ? text.split(/\\W+/g) : Array.from(text);\n  \n  const data = d3.rollups(words, size, w => w)\n    .sort(([, a], [, b]) => d3.descending(a, b))\n    .slice(0, maxWords)\n    .map(([key, size]) => ({text: word(key), size}));\n  \n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, 0, width, height])\n      .attr(\"width\", width)\n      .attr(\"font-family\", fontFamily)\n      .attr(\"text-anchor\", \"middle\")\n      .attr(\"fill\", \"#962e2ec8\") \n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n      .text(title);\n\n  const g = svg.append(\"g\").attr(\"transform\", `translate(${marginLeft},${marginTop})`);\n\n  const cloud = d3Cloud()\n      .size([width - marginLeft - marginRight, height - marginTop - marginBottom])\n      .words(data)\n      .padding(padding)\n      .rotate(rotate)\n      .font(fontFamily)\n      .fontSize(d => Math.sqrt(d.size) * fontScale)\n      .on(\"word\", ({size, x, y, rotate, text}) => {\n        g.append(\"text\")\n            .attr(\"font-size\", size)\n            .attr(\"transform\", `translate(${x},${y}) rotate(${rotate})`)\n            .text(text);\n      });\n\n  cloud.start();\n  invalidation && invalidation.then(() => cloud.stop());\n  return svg.node();\n}\nWordCloud(\"Bicycle\",\"bike bike bike bike bike bike bike bike bike bike bike bike bike get get get get get get one one one one lanes lanes lanes lanes good good good good trail trail trail trail st st st lane lane lane park park park like like like street street street city city mbt mbt bikes bikes many many ride ride trails trails way way pretty pretty people people th th go go rock rock creek creek nw nw map map take take lock lock want want much much\", {\n  width: 250,\n  height: 100,\n  size: () => .3 + Math.random(),\n  rotate: () => (~~(Math.random() * 6) - 3) * 30\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode development was performed by the authors of this project based on the assignments of the 503 course and the next tutorials: - Network D3 - Choropleth Altair - Plotly Scatter  - Plotly Boxplot  - Plotly histogram  - Plotly Distplot"
  },
  {
    "objectID": "index.html#what-is-metro-ridership-in-washington-d.c.-like",
    "href": "index.html#what-is-metro-ridership-in-washington-d.c.-like",
    "title": "Walkability in D.C.",
    "section": "4. What is metro ridership in Washington, D.C. like?",
    "text": "4. What is metro ridership in Washington, D.C. like?\n\n\nCode\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\nraw_data_dir = Path().absolute().parent.absolute().parent/\"data\"/\"raw_data\"\n\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nwrite_data_dir = data_dir/\"cleaned_data\"\n\n# Read in data\ndf = pd.read_csv(raw_data_dir/'wmata.csv', encoding='utf-16', delimiter=\"\\t\")\n\n# Remove columns Servicetype_This_Year(group), Holiday_Last_Year, Holiday_This_Year, Servicetype_This_Year, Time_Period, and Date_Last_Year\ndf = df.drop(['Day_of_Date_This_Year', 'Servicetype_This_Year_(group)', 'Holiday_Last_Year', 'Holiday_This_Year', 'Servicetype_This_Year', 'Time_Period', 'Date_Last_Year', 'Entries_Last_Year'], axis=1)\n\n# Rename columns \ndf = df.rename(columns={'Date_This_Year': 'Date'})\ndf = df.rename(columns={'Entries_This_Year': 'Entries'})\n\n# Pivot data\npivot_df = df.pivot_table(index='Date', columns='Station', values='Entries')\n\n# Convert index of pivot_df to datetime\npivot_df.index = pd.to_datetime(pivot_df.index)\n\n# Organize index of pivot_df from earliest to latest date\npivot_df = pivot_df.sort_index()\n\n# Select stations Anacostia, Stadium-Armory, Van Ness-UDC, Shaw-Howard Univ, Gallery Place, and Capitol South from pivot_df\nnew_df = pivot_df[['Anacostia', 'Stadium-Armory', 'Van Ness-UDC', 'Shaw-Howard U', 'Gallery Place', 'Capitol South']]\n\n\n# Save pivot_df and new_df to csv\npivot_df.to_csv(write_data_dir/'wmata_cleaned.csv')\nnew_df.to_csv(write_data_dir/'wmata_new_cleaned.csv')\n\n# Build interactive timeseries plot using plotly\n# Import libraries\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# List all stations\nstations = list(new_df.columns)\n\n#Select theming colors \n\ncolors_markers = ['rgb(110, 4, 18)','rgb(214, 163, 32)','rgb(181,107,181)','rgb(196,87,80)','rgb(117, 79, 68)','rgb(128, 126, 46)']\n\n# Create subplot with one trace per station\nfig = make_subplots(rows=1, cols=1)\nij = 0\nfor station in stations:\n    fig.add_trace(\n        go.Scatter(x=new_df.index,\n        y=new_df[station],\n        name=station,\n        marker=dict(color=colors_markers[ij])\n        ),\n        row=1, \n        col=1,\n    )\n    ij += 1\n\n# Create dropdown menu to select station\nbuttons = []\nfor station in stations:\n    buttons.append(\n        dict(method='update', label=station, args=[{'visible': [station == s for s in stations]}])\n    )\ndropdown = dict(\n    active=0, buttons=buttons, direction='down', showactive=True, x=1.1, y=1.1\n)\n\n# Update layout\n\nfont_dict=dict(family='Arial',\n               size=14,\n               color='black'\n               )\nfig.update_layout(\n    updatemenus=[dropdown], height=600, width=600,\n    title='WMATA Metro Entries by Selected Station and Date in March 2023', xaxis_title='Date', yaxis_title='Entries',\n    yaxis=dict(range=[0, 3000]),\n    font=font_dict\n)\n# Change background color to defined colors\nfig.update_layout(\n    plot_bgcolor='rgb(230, 230, 230)'\n)\n\n# Show plot\nfig.show()\n\n#### Table\nfrom IPython.display import display, HTML\n\ndata_dir = Path().absolute().parent.absolute().parent/\"data\"\nwrite_data_dir = data_dir/\"cleaned_data\"\n\ndf = pd.read_csv(write_data_dir / 'wmata_long_cleaned.csv')\ndf.Date = pd.to_datetime(df.Date)\nweekly_df = df.groupby([pd.Grouper(key = 'Date', freq = 'W'), 'Station'])['Entries'].sum().reset_index()\n# sort so that the one with most ridership per week is on top\nweekly_df = weekly_df.sort_values(by=['Date', 'Entries'], ascending=[True, False])\n# format the dates so they look cleaner in the table\nweekly_df.Date = weekly_df.Date.dt.strftime('%B %-d')\n# format number of rides\nweekly_df['Entries'] = weekly_df['Entries'].apply(lambda x: \"{:,}\".format(int(x)))\nheaderColor = '#962E2E' # red part of theme\nrowEvenColor = '#FDE6AB' # ligher yellow part of theme\nrowEvenColor2 = 'lightgray' # ligher yellow part of theme\nrowOddColor = 'white'\nnum_stations = weekly_df.Station.nunique()\nnum_days = weekly_df.Date.nunique()\ntable_fig = go.Figure(data=[go.Table(\n  header=dict(\n    values=['Start of Week', 'Metro Station', 'Num. of Riders over 7 Days'],\n    line_color='darkslategray',\n    fill_color=headerColor,\n    align=['center'],\n    font=dict(color='white', size=12)\n  ),\n  cells=dict(\n    values=[weekly_df.Date, weekly_df.Station, weekly_df.Entries],\n    line_color='darkslategray',\n    # 2-D list of colors for alternating rows\n    fill_color = [[rowOddColor,rowEvenColor]*(int(len(df)/2)+len(df)%2)],\n    # fill_color = [([rowOddColor]*num_stations+[rowEvenColor]*num_stations)*(int(num_days/2)+ (num_days%2))],\n    # fill_color = [([rowOddColor,rowEvenColor]*(int(num_stations/2)+(num_stations%2))+[rowOddColor,rowEvenColor2]*(int(num_stations/2)+(num_stations%2)))*(int(len(df)/(num_stations*2)) + len(df)%(num_stations*2))],\n    align = ['center'],\n    font = dict(color = 'darkslategray', size = 11)\n    ))\n])\ntable_fig.update_layout(title_text = 'Weekly D.C. Metro Ridership',font=font_dict)\ntable_fig.update_layout({'margin': {'t': 50\n                        }})\ntable_fig.show()\n# table_fig = go.Figure(data=[go.Table(\n#     header=dict(values=list(df.columns),\n#                 fill_color=\"#962E2E\",\n#                 align='left'),\n#     cells=dict(values=[df.Date, df.Station, df.Entries],\n#                fill_color='#FDFDFD',\n#                align='left'))\n# ])\n# table_fig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nAfter analyzing accessibility by foot and bike, we wanted to explore another dimension of walkability–the metro. In Washington, D.C. the metro is established and managed by the Washington Metropolitan Area Transit Authority (WMATA).\nThe plotly graph above shows the number of entries at the metro stations in the Washington, D.C. area in March 2023. The data is from the Metrorail Ridership Year-over-Year Change data here. The graph shows number of entries at a station on various days in March 2023. Initially, the plot shows six stations’ entries by day. These six stations were included because they are located on some of the most and least walkable neighborhoods in Washington, D.C. The legend at the right shows you the six different stations for which there is ridership data. The plot is interactive, so you can select a specific station at the dropdown menu at the top right corner. Upon selecting it, the graph will reflect the selected station’s entries by day. You can also hover over each line where a tooltip will reveal the selected day and station as well as the number of entries accordingly. The graph is also zoomable, so you can zoom in and out to see the data more clearly. While the plot only shows six stations; however, if you want to learn more about ridership data in other stations, you can examine the table above for more details.\nOverall, we see that there is a weekly pattern in ridership, where generally there are more entries on weekdays than weekends across almost all stations. This is perhaps due to the use of the metro to commute to work and activites on weekdays. Furthermore, we also observe that Gallery Place and Capitol South, which are located in tracts with higher walkability scores according to Census data have higher ridership, have significantly higher ridership than the other stations. On the contrary, Anacostia, Stadium-Armory, and Van Ness-UDC, which are located in tracts with lower walkability scores according to Census data have lower ridership. This makes sense, because stations with higher ridership are likely to be located in more walkable neighborhoods where amenities like public transport are more well-connected and accessible, whereas the opposite is the case for less walkable neighborhoods. Note also that Capitol South is located on Capitol Hill, which is a major tourist attraction and office area in Washington, D.C. and Gallery Place is located in Chinatown, which is also a major tourist attraction. These are less residential neighborhoods.\nThe data is limited in that there is no data on exits at a station, so the data only shows one direction of a journey––though it is appropriate to assume that a rider will likely exit at the station at the end of the day. Furthermore, the data is limited in that it only shows data for one month in 2023, so it is not representative of ridership in other months or years. However, it is still useful to see the ridership patterns in March 2023."
  },
  {
    "objectID": "authors.html",
    "href": "authors.html",
    "title": "Authors",
    "section": "",
    "text": "Corrina Calanoc\n\n  \n\nCynthia Ng\n\n  \n\nKatherine Mead\n\n  \n\nMadelyne Ventura\n\n  \n\nValeria Vera Lagos"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Walkability in D.C.",
    "section": "Introduction",
    "text": "Introduction\nWalkability is defined as the ease with which people can access amenities in a place without the use of cars. Walkability is associated with equitable access to key resources as well as positive outcomes in health, social bonding and community-building, sustainability, and the economy. While urban areas in the US initially developed around transportation by foot, the mass introduction of cars and motorized vehicles in the 1950s led to urban sprawl, which is an expansion pattern consisting of low-density areas and car-dependent lifestyles1. A report by the Institute for Transportation and Development Policy evaluated the walkability of nearly 1,000 cities globally. The report placed London, Hong Kong, Paris, and Bogotá as cities with highest walkability scores and U.S. cities particularly low on the list as a result of urban sprawl2.\nThe same report found that the only city in the US to make the top 25 in any category was Washington, D.C. Our personal experience living in Washington, D.C. also mirrors the fact that Washington, D.C. seems like a relatively walkable city compared to other cities in the US. Some of us have also lived in walkable cities around the world and saw first-hand the impact of high walkability on well-being. As our graduate program has brought us together from around the world to Washington, D.C., it would not just be professionally rewarding, but also personally meaningful to explore the city’s walkability.\nTo explore this topic further, we aim to answer the following data science questions:\n\nHow is walkabilty associated with socioeconomic outcomes in Washington, D.C.?\nHow is walkability associated with health outcomes in Washington, D.C.?\nHow accessible are neighborhoods in Washington, D.C. by bike?\nWhat is metro ridership in Washington, D.C. like?\nWhat is public sentiment around walkability in Washington, D.C.?\n\nWe answer these questions by first collecting, cleaning, and exploring US Census Tract, Capital Bike Share, PLACES Census Health Data Estimation, Washington Metro (WMATA) ridership, and Reddit data. Based on our initial data exploration, we investigate the ease of access of different neighborhoods, or census tracts, by foot, which is our primary measure of walkability. We also explore the correlation between walkability in different tracts and social and health outcomes. We then proceed to investigate the ease of access of tracts by bike by examining the distribution of Capital Bike Share stations and buffered bike lanes throughout the city. Next, we look at the usage of the WMATA metro. Finally, we check sentiment around walkability in the city by analyzing Reddit threads related to this topic.\nTo learn more about the methodology, please visit our methods page."
  }
]